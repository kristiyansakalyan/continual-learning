{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/notebooks/venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/notebooks/venv/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "from utils.common import (\n",
    "    m2f_dataset_collate,\n",
    "    m2f_extract_pred_maps_and_masks,\n",
    "    BG_VALUE_255,\n",
    "    set_seed,\n",
    "    pixel_mean_std,\n",
    "    CADIS_PIXEL_MEAN,\n",
    "    CADIS_PIXEL_STD,\n",
    "    CAT1K_PIXEL_MEAN,\n",
    "    CAT1K_PIXEL_STD,\n",
    ")\n",
    "from utils.dataset_utils import (\n",
    "    get_cadisv2_dataset,\n",
    "    get_cataract1k_dataset,\n",
    "    ZEISS_CATEGORIES,\n",
    ")\n",
    "from utils.medical_datasets import Mask2FormerDataset\n",
    "from transformers import (\n",
    "    Mask2FormerForUniversalSegmentation,\n",
    "    SwinModel,\n",
    "    SwinConfig,\n",
    "    Mask2FormerConfig,\n",
    "    AutoImageProcessor,\n",
    "    Mask2FormerImageProcessor\n",
    ")\n",
    "from torch.utils.data import DataLoader\n",
    "import evaluate\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import numpy as np\n",
    "from dotenv import load_dotenv\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "set_seed(42) # seed everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/notebooks/venv/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not Matched: hidden_states_norms.stage1.weight != layernorm.weight\n",
      "Not Matched: hidden_states_norms.stage1.bias != layernorm.bias\n"
     ]
    }
   ],
   "source": [
    "NUM_CLASSES = len(ZEISS_CATEGORIES) - 3  # Remove class incremental\n",
    "SWIN_BACKBONE = \"microsoft/swin-tiny-patch4-window7-224\"#\"microsoft/swin-large-patch4-window12-384\"\n",
    "\n",
    "# Download pretrained swin model\n",
    "swin_model = SwinModel.from_pretrained(\n",
    "    SWIN_BACKBONE, out_features=[\"stage1\", \"stage2\", \"stage3\", \"stage4\"]\n",
    ")\n",
    "swin_config = SwinConfig.from_pretrained(\n",
    "    SWIN_BACKBONE, out_features=[\"stage1\", \"stage2\", \"stage3\", \"stage4\"]\n",
    ")\n",
    "\n",
    "# Create Mask2Former configuration based on Swin's configuration\n",
    "mask2former_config = Mask2FormerConfig(\n",
    "    backbone_config=swin_config, num_labels=NUM_CLASSES #, ignore_value=BG_VALUE\n",
    ")\n",
    "\n",
    "# Create the Mask2Former model with this configuration\n",
    "model = Mask2FormerForUniversalSegmentation(mask2former_config)\n",
    "\n",
    "# Reuse pretrained parameters\n",
    "for swin_param, m2f_param in zip(\n",
    "    swin_model.named_parameters(),\n",
    "    model.model.pixel_level_module.encoder.named_parameters(),\n",
    "):\n",
    "    m2f_param_name = f\"model.pixel_level_module.encoder.{m2f_param[0]}\"\n",
    "\n",
    "    if swin_param[0] == m2f_param[0]:\n",
    "        model.state_dict()[m2f_param_name].copy_(swin_param[1])\n",
    "        continue\n",
    "\n",
    "    print(f\"Not Matched: {m2f_param[0]} != {swin_param[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/notebooks/venv/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Could not find image processor class in the image processor config or the model config. Loading based on pattern matching with the model's feature extractor configuration. Please open a PR/issue to update `preprocessor_config.json` to use `image_processor_type` instead of `feature_extractor_type`. This warning will be removed in v4.40.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'A': {'train': <torch.utils.data.dataloader.DataLoader object at 0x7fb28515d0a0>, 'val': <torch.utils.data.dataloader.DataLoader object at 0x7fb285aeaf30>, 'test': <torch.utils.data.dataloader.DataLoader object at 0x7fb28515e390>}, 'B': {'train': <torch.utils.data.dataloader.DataLoader object at 0x7fb28515d1f0>, 'val': <torch.utils.data.dataloader.DataLoader object at 0x7fb28515d8e0>, 'test': <torch.utils.data.dataloader.DataLoader object at 0x7fb28515c3e0>}}\n"
     ]
    }
   ],
   "source": [
    "# Helper function to load datasets\n",
    "def load_dataset(dataset_getter, data_path, domain_incremental):\n",
    "    return dataset_getter(data_path, domain_incremental=domain_incremental)\n",
    "\n",
    "\n",
    "# Helper function to create dataloaders for a dataset\n",
    "def create_dataloaders(\n",
    "    dataset, batch_size, shuffle, num_workers, drop_last, pin_memory, collate_fn\n",
    "):\n",
    "    return {\n",
    "        \"train\": DataLoader(\n",
    "            dataset[\"train\"],\n",
    "            batch_size=batch_size,\n",
    "            shuffle=shuffle,\n",
    "            num_workers=num_workers,\n",
    "            drop_last=drop_last,\n",
    "            pin_memory=pin_memory,\n",
    "            collate_fn=collate_fn,\n",
    "        ),\n",
    "        \"val\": DataLoader(\n",
    "            dataset[\"val\"],\n",
    "            batch_size=batch_size,\n",
    "            shuffle=shuffle,\n",
    "            num_workers=num_workers,\n",
    "            drop_last=drop_last,\n",
    "            pin_memory=pin_memory,\n",
    "            collate_fn=collate_fn,\n",
    "        ),\n",
    "        \"test\": DataLoader(\n",
    "            dataset[\"test\"],\n",
    "            batch_size=batch_size,\n",
    "            shuffle=shuffle,\n",
    "            num_workers=num_workers,\n",
    "            drop_last=drop_last,\n",
    "            pin_memory=pin_memory,\n",
    "            collate_fn=collate_fn,\n",
    "        ),\n",
    "    }\n",
    "\n",
    "\n",
    "# Load datasets\n",
    "datasets = {\n",
    "    \"A\": load_dataset(get_cadisv2_dataset, \"../../storage/data/CaDISv2\", True),\n",
    "    \"B\": load_dataset(get_cataract1k_dataset, \"../../storage/data/cataract-1k\", True),\n",
    "}\n",
    "\n",
    "# pixel_mean_A,pixel_std_A=pixel_mean_std(datasets[\"A\"][0])\n",
    "pixel_mean_A = CADIS_PIXEL_MEAN\n",
    "pixel_std_A = CADIS_PIXEL_STD\n",
    "\n",
    "# pixel_mean_B,pixel_std_B=pixel_mean_std(datasets[\"B\"][0])\n",
    "pixel_mean_B = CAT1K_PIXEL_MEAN\n",
    "pixel_std_B = CAT1K_PIXEL_STD\n",
    "\n",
    "# Define preprocessor\n",
    "swin_processor = AutoImageProcessor.from_pretrained(SWIN_BACKBONE)\n",
    "m2f_preprocessor_A = Mask2FormerImageProcessor(\n",
    "    reduce_labels=True,\n",
    "    ignore_index=255,\n",
    "    do_resize=False,\n",
    "    do_rescale=True,\n",
    "    do_normalize=True,\n",
    "    image_std=pixel_std_A,\n",
    "    image_mean=pixel_mean_A,\n",
    ")\n",
    "\n",
    "m2f_preprocessor_B = Mask2FormerImageProcessor(\n",
    "    reduce_labels=True,\n",
    "    ignore_index=255,\n",
    "    do_resize=False,\n",
    "    do_rescale=True,\n",
    "    do_normalize=True,\n",
    "    image_std=pixel_std_B,\n",
    "    image_mean=pixel_mean_B,\n",
    ")\n",
    "\n",
    "# Create Mask2Former Datasets\n",
    "m2f_datasets = {\n",
    "    \"A\": {\n",
    "        \"train\": Mask2FormerDataset(datasets[\"A\"][0], m2f_preprocessor_A),\n",
    "        \"val\": Mask2FormerDataset(datasets[\"A\"][1], m2f_preprocessor_A),\n",
    "        \"test\": Mask2FormerDataset(datasets[\"A\"][2], m2f_preprocessor_A),\n",
    "    },\n",
    "    \"B\": {\n",
    "        \"train\": Mask2FormerDataset(datasets[\"B\"][0], m2f_preprocessor_B),\n",
    "        \"val\": Mask2FormerDataset(datasets[\"B\"][1], m2f_preprocessor_B),\n",
    "        \"test\": Mask2FormerDataset(datasets[\"B\"][2], m2f_preprocessor_B),\n",
    "    },\n",
    "}\n",
    "\n",
    "# DataLoader parameters\n",
    "N_WORKERS = 4\n",
    "BATCH_SIZE = 16\n",
    "SHUFFLE = True\n",
    "DROP_LAST = True\n",
    "\n",
    "dataloader_params = {\n",
    "    \"batch_size\": BATCH_SIZE,\n",
    "    \"shuffle\": SHUFFLE,\n",
    "    \"num_workers\": N_WORKERS,\n",
    "    \"drop_last\": DROP_LAST,\n",
    "    \"pin_memory\": True,\n",
    "    \"collate_fn\": m2f_dataset_collate,\n",
    "}\n",
    "\n",
    "# Create DataLoaders\n",
    "dataloaders = {\n",
    "    key: create_dataloaders(m2f_datasets[key], **dataloader_params)\n",
    "    for key in m2f_datasets\n",
    "}\n",
    "\n",
    "print(dataloaders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Check if CUDA is available, otherwise use CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 1160), started 0:03:23 ago. (Use '!kill 1160' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-1c80317fa3b1799d\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-1c80317fa3b1799d\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Tensorboard setup\n",
    "out_dir=\"outputs/\"\n",
    "if not os.path.exists(out_dir):\n",
    "    os.makedirs(out_dir)\n",
    "if not os.path.exists(out_dir+\"runs\"):\n",
    "    os.makedirs(out_dir+\"runs\")\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir outputs/runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-09T15:53:04.836611Z",
     "iopub.status.busy": "2024-05-09T15:53:04.835993Z",
     "iopub.status.idle": "2024-05-09T15:53:04.934270Z",
     "shell.execute_reply": "2024-05-09T15:53:04.932854Z",
     "shell.execute_reply.started": "2024-05-09T15:53:04.836570Z"
    }
   },
   "outputs": [],
   "source": [
    "#!CUDA_LAUNCH_BLOCKING=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# First train on dataset A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Training\n",
    "NUM_EPOCHS = 110 #200\n",
    "LEARNING_RATE = 1e-4\n",
    "LR_MULTIPLIER = 0.1\n",
    "BACKBONE_LR = LEARNING_RATE * LR_MULTIPLIER\n",
    "WEIGHT_DECAY = 0.05\n",
    "metric = evaluate.load(\"mean_iou\")\n",
    "encoder_params = [\n",
    "    param\n",
    "    for name, param in model.named_parameters()\n",
    "    if name.startswith(\"model.pixel_level_module.encoder\")\n",
    "]\n",
    "decoder_params = [\n",
    "    param\n",
    "    for name, param in model.named_parameters()\n",
    "    if name.startswith(\"model.pixel_level_module.decoder\")\n",
    "]\n",
    "transformer_params = [\n",
    "    param\n",
    "    for name, param in model.named_parameters()\n",
    "    if name.startswith(\"model.transformer_module\")\n",
    "]\n",
    "optimizer = optim.AdamW(\n",
    "    [\n",
    "        {\"params\": encoder_params, \"lr\": BACKBONE_LR},\n",
    "        {\"params\": decoder_params},\n",
    "        {\"params\": transformer_params},\n",
    "    ],\n",
    "    lr=LEARNING_RATE,\n",
    "    weight_decay=WEIGHT_DECAY,\n",
    ")\n",
    "\n",
    "scheduler = optim.lr_scheduler.PolynomialLR(\n",
    "    optimizer, total_iters=NUM_EPOCHS, power=0.9\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mge85ket\u001b[0m (\u001b[33mcontinual-learning-tum\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# WandB for team usage !!!!\n",
    "\n",
    "wandb.login() # use this one if a different person is going to run the notebook\n",
    "#wandb.login(relogin=False) # if the same person in the last run is going to run the notebook again\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/notebooks/continual-learning/wandb/run-20240517_120558-vfh7zerl</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/continual-learning-tum/M2F_original/runs/vfh7zerl' target=\"_blank\">M2F-Swin-Tiny-Train_Cataract1K</a></strong> to <a href='https://wandb.ai/continual-learning-tum/M2F_original' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/continual-learning-tum/M2F_original' target=\"_blank\">https://wandb.ai/continual-learning-tum/M2F_original</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/continual-learning-tum/M2F_original/runs/vfh7zerl' target=\"_blank\">https://wandb.ai/continual-learning-tum/M2F_original/runs/vfh7zerl</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/continual-learning-tum/M2F_original/runs/vfh7zerl?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7fb2801fec30>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(\n",
    "    project=\"M2F_original\",\n",
    "    config={\n",
    "        \"learning_rate\": LEARNING_RATE,\n",
    "        \"learning_rate_multiplier\": LR_MULTIPLIER,\n",
    "        \"backbone_learning_rate\": BACKBONE_LR,\n",
    "        \"learning_rate_scheduler\": scheduler.__class__.__name__,\n",
    "        \"optimizer\": optimizer.__class__.__name__,\n",
    "        \"backbone\": SWIN_BACKBONE,\n",
    "        \"m2f_preprocessor\": m2f_preprocessor_B.__dict__,\n",
    "        \"m2f_model_config\": model.config\n",
    "    },\n",
    "    name=\"M2F-Swin-Tiny-Train_Cataract1K\",\n",
    "    notes=\"M2F with tiny Swin backbone pretrained on ImageNet-1K. \\\n",
    "        Scenario: Train on B, Test on B\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Tensorboard logging\n",
    "writer = SummaryWriter(log_dir=out_dir + \"runs\")\n",
    "\n",
    "# Model checkpointing\n",
    "base_model_name=\"m2f_swin_backbone_train_cataract1k\"\n",
    "model_dir = out_dir + \"models/\"\n",
    "if not os.path.exists(model_dir):\n",
    "    print(\"Store weights in: \", model_dir)\n",
    "    os.makedirs(model_dir)\n",
    "\n",
    "best_model_dir = model_dir + f\"{base_model_name}/best_model/\"\n",
    "if not os.path.exists(best_model_dir):\n",
    "    print(\"Store best model weights in: \", best_model_dir)\n",
    "    os.makedirs(best_model_dir)\n",
    "final_model_dir = model_dir + f\"{base_model_name}/final_model/\"\n",
    "if not os.path.exists(final_model_dir):\n",
    "    print(\"Store final model weights in: \", final_model_dir)\n",
    "    os.makedirs(final_model_dir)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['outputs/models/m2f_swin_backbone_train_cataract1k/preprocessor_config.json']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the preprocessor\n",
    "m2f_preprocessor_B.save_pretrained(model_dir + base_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/110 Training: 100%|██████████| 112/112 [06:32<00:00,  3.51s/it, loss=975.0126] \n",
      "/root/.cache/huggingface/modules/evaluate_modules/metrics/evaluate-metric--mean_iou/9e450724f21f05592bfb0255fe2fa576df8171fa060d11121d8aecfff0db80d0/mean_iou.py:259: RuntimeWarning: invalid value encountered in divide\n",
      "  iou = total_area_intersect / total_area_union\n",
      "/root/.cache/huggingface/modules/evaluate_modules/metrics/evaluate-metric--mean_iou/9e450724f21f05592bfb0255fe2fa576df8171fa060d11121d8aecfff0db80d0/mean_iou.py:260: RuntimeWarning: invalid value encountered in divide\n",
      "  acc = total_area_intersect / total_area_label\n",
      "Epoch 1/110 Validation: 100%|██████████| 14/14 [00:42<00:00,  3.03s/it, loss=1006.0431]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/110, Train Loss: 75.3267, Train mIoU: 0.0618, Validation Loss: 62.1338, Validation mIoU: 0.0665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/110 Training: 100%|██████████| 112/112 [06:06<00:00,  3.28s/it, loss=461.8261]\n",
      "Epoch 2/110 Validation: 100%|██████████| 14/14 [00:40<00:00,  2.88s/it, loss=442.4552]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/110, Train Loss: 45.4344, Train mIoU: 0.1487, Validation Loss: 29.5133, Validation mIoU: 0.2229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/110 Training: 100%|██████████| 112/112 [06:15<00:00,  3.36s/it, loss=266.4327]\n",
      "Epoch 3/110 Validation: 100%|██████████| 14/14 [00:42<00:00,  3.07s/it, loss=306.1015]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/110, Train Loss: 24.0933, Train mIoU: 0.2890, Validation Loss: 17.5510, Validation mIoU: 0.3621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/110 Training: 100%|██████████| 112/112 [06:14<00:00,  3.34s/it, loss=219.0459]\n",
      "Epoch 4/110 Validation: 100%|██████████| 14/14 [00:40<00:00,  2.90s/it, loss=210.8945]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/110, Train Loss: 16.4646, Train mIoU: 0.4183, Validation Loss: 14.8467, Validation mIoU: 0.4480\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/110 Training: 100%|██████████| 112/112 [06:13<00:00,  3.34s/it, loss=262.1952]\n",
      "Epoch 5/110 Validation: 100%|██████████| 14/14 [00:40<00:00,  2.92s/it, loss=190.0068]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/110, Train Loss: 14.1583, Train mIoU: 0.5064, Validation Loss: 13.2606, Validation mIoU: 0.4753\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/110 Training: 100%|██████████| 112/112 [06:15<00:00,  3.35s/it, loss=169.2522]\n",
      "Epoch 6/110 Validation: 100%|██████████| 14/14 [00:36<00:00,  2.63s/it, loss=158.6317]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/110, Train Loss: 12.5061, Train mIoU: 0.5331, Validation Loss: 11.7312, Validation mIoU: 0.5403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/110 Training: 100%|██████████| 112/112 [06:25<00:00,  3.44s/it, loss=189.6375]\n",
      "Epoch 7/110 Validation: 100%|██████████| 14/14 [00:43<00:00,  3.08s/it, loss=185.6576]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/110, Train Loss: 11.9068, Train mIoU: 0.5939, Validation Loss: 12.0291, Validation mIoU: 0.5276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/110 Training: 100%|██████████| 112/112 [06:13<00:00,  3.33s/it, loss=178.7290]\n",
      "Epoch 8/110 Validation: 100%|██████████| 14/14 [00:39<00:00,  2.79s/it, loss=181.7968]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/110, Train Loss: 10.8959, Train mIoU: 0.6339, Validation Loss: 11.3294, Validation mIoU: 0.5657\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/110 Training: 100%|██████████| 112/112 [06:09<00:00,  3.30s/it, loss=199.5288]\n",
      "Epoch 9/110 Validation: 100%|██████████| 14/14 [00:38<00:00,  2.76s/it, loss=160.8610]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/110, Train Loss: 10.1826, Train mIoU: 0.7084, Validation Loss: 11.5274, Validation mIoU: 0.6590\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/110 Training: 100%|██████████| 112/112 [06:15<00:00,  3.35s/it, loss=143.8205]\n",
      "Epoch 10/110 Validation: 100%|██████████| 14/14 [00:39<00:00,  2.82s/it, loss=188.2857]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/110, Train Loss: 9.3202, Train mIoU: 0.7442, Validation Loss: 9.7845, Validation mIoU: 0.7257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/110 Training: 100%|██████████| 112/112 [06:08<00:00,  3.29s/it, loss=138.0228]\n",
      "Epoch 11/110 Validation: 100%|██████████| 14/14 [00:40<00:00,  2.92s/it, loss=144.9584]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/110, Train Loss: 8.6737, Train mIoU: 0.7733, Validation Loss: 9.2874, Validation mIoU: 0.7604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/110 Training: 100%|██████████| 112/112 [06:03<00:00,  3.25s/it, loss=118.3179]\n",
      "Epoch 12/110 Validation: 100%|██████████| 14/14 [00:37<00:00,  2.69s/it, loss=178.5293]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/110, Train Loss: 8.2745, Train mIoU: 0.7976, Validation Loss: 9.2222, Validation mIoU: 0.8045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/110 Training: 100%|██████████| 112/112 [06:02<00:00,  3.23s/it, loss=134.6131]\n",
      "Epoch 13/110 Validation: 100%|██████████| 14/14 [00:40<00:00,  2.91s/it, loss=135.1642]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/110, Train Loss: 7.9321, Train mIoU: 0.7999, Validation Loss: 8.9584, Validation mIoU: 0.8022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/110 Training: 100%|██████████| 112/112 [06:07<00:00,  3.28s/it, loss=135.4963]\n",
      "Epoch 14/110 Validation: 100%|██████████| 14/14 [00:39<00:00,  2.85s/it, loss=130.4563]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/110, Train Loss: 7.4877, Train mIoU: 0.8339, Validation Loss: 9.2101, Validation mIoU: 0.7164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/110 Training: 100%|██████████| 112/112 [06:14<00:00,  3.34s/it, loss=123.4660]\n",
      "Epoch 15/110 Validation: 100%|██████████| 14/14 [00:39<00:00,  2.84s/it, loss=135.2343]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/110, Train Loss: 7.3631, Train mIoU: 0.8319, Validation Loss: 8.6883, Validation mIoU: 0.7617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/110 Training: 100%|██████████| 112/112 [06:02<00:00,  3.24s/it, loss=146.7481]\n",
      "Epoch 16/110 Validation: 100%|██████████| 14/14 [00:38<00:00,  2.73s/it, loss=130.6294]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/110, Train Loss: 8.7848, Train mIoU: 0.7975, Validation Loss: 9.5053, Validation mIoU: 0.7549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/110 Training: 100%|██████████| 112/112 [06:03<00:00,  3.25s/it, loss=131.3831]\n",
      "Epoch 17/110 Validation: 100%|██████████| 14/14 [00:43<00:00,  3.13s/it, loss=143.1883]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/110, Train Loss: 8.1424, Train mIoU: 0.8340, Validation Loss: 10.1808, Validation mIoU: 0.7296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/110 Training: 100%|██████████| 112/112 [06:05<00:00,  3.27s/it, loss=105.6142]\n",
      "Epoch 18/110 Validation: 100%|██████████| 14/14 [00:42<00:00,  3.04s/it, loss=155.7063]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/110, Train Loss: 7.9686, Train mIoU: 0.8031, Validation Loss: 8.7772, Validation mIoU: 0.7213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/110 Training: 100%|██████████| 112/112 [06:03<00:00,  3.25s/it, loss=107.9434]\n",
      "Epoch 19/110 Validation: 100%|██████████| 14/14 [00:42<00:00,  3.01s/it, loss=179.7084]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/110, Train Loss: 7.6105, Train mIoU: 0.8204, Validation Loss: 8.6651, Validation mIoU: 0.7385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/110 Training: 100%|██████████| 112/112 [06:01<00:00,  3.23s/it, loss=109.3766]\n",
      "Epoch 20/110 Validation: 100%|██████████| 14/14 [00:40<00:00,  2.89s/it, loss=131.6930]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/110, Train Loss: 6.6917, Train mIoU: 0.8366, Validation Loss: 8.8586, Validation mIoU: 0.7657\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/110 Training: 100%|██████████| 112/112 [06:13<00:00,  3.34s/it, loss=92.8285] \n",
      "Epoch 21/110 Validation: 100%|██████████| 14/14 [00:40<00:00,  2.86s/it, loss=131.5689]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/110, Train Loss: 6.6017, Train mIoU: 0.8489, Validation Loss: 8.4139, Validation mIoU: 0.8195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22/110 Training: 100%|██████████| 112/112 [06:20<00:00,  3.40s/it, loss=93.8675] \n",
      "Epoch 22/110 Validation: 100%|██████████| 14/14 [00:42<00:00,  3.01s/it, loss=114.3569]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/110, Train Loss: 6.4940, Train mIoU: 0.8516, Validation Loss: 8.1034, Validation mIoU: 0.8060\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23/110 Training: 100%|██████████| 112/112 [06:03<00:00,  3.24s/it, loss=86.4454] \n",
      "Epoch 23/110 Validation: 100%|██████████| 14/14 [00:41<00:00,  2.99s/it, loss=111.6324]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/110, Train Loss: 6.3260, Train mIoU: 0.8548, Validation Loss: 8.4268, Validation mIoU: 0.8017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24/110 Training: 100%|██████████| 112/112 [06:04<00:00,  3.25s/it, loss=96.1467] \n",
      "Epoch 24/110 Validation: 100%|██████████| 14/14 [00:42<00:00,  3.01s/it, loss=172.8296]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/110, Train Loss: 6.2367, Train mIoU: 0.8508, Validation Loss: 7.9212, Validation mIoU: 0.7320\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25/110 Training: 100%|██████████| 112/112 [06:03<00:00,  3.25s/it, loss=86.6870] \n",
      "Epoch 25/110 Validation: 100%|██████████| 14/14 [00:41<00:00,  2.97s/it, loss=106.4672]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/110, Train Loss: 6.1768, Train mIoU: 0.8565, Validation Loss: 8.3396, Validation mIoU: 0.7315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26/110 Training: 100%|██████████| 112/112 [06:11<00:00,  3.32s/it, loss=86.2516] \n",
      "Epoch 26/110 Validation: 100%|██████████| 14/14 [00:41<00:00,  2.95s/it, loss=149.0842]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/110, Train Loss: 5.8611, Train mIoU: 0.8657, Validation Loss: 7.8289, Validation mIoU: 0.8096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27/110 Training: 100%|██████████| 112/112 [06:20<00:00,  3.39s/it, loss=88.5464] \n",
      "Epoch 27/110 Validation: 100%|██████████| 14/14 [00:45<00:00,  3.23s/it, loss=113.5185]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/110, Train Loss: 5.7306, Train mIoU: 0.8602, Validation Loss: 8.0084, Validation mIoU: 0.7992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28/110 Training: 100%|██████████| 112/112 [06:09<00:00,  3.30s/it, loss=85.1345] \n",
      "Epoch 28/110 Validation: 100%|██████████| 14/14 [00:44<00:00,  3.17s/it, loss=152.1606]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/110, Train Loss: 5.7190, Train mIoU: 0.8643, Validation Loss: 8.5803, Validation mIoU: 0.7827\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29/110 Training: 100%|██████████| 112/112 [06:19<00:00,  3.39s/it, loss=89.2868] \n",
      "Epoch 29/110 Validation: 100%|██████████| 14/14 [00:43<00:00,  3.08s/it, loss=127.2457]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/110, Train Loss: 5.6806, Train mIoU: 0.8722, Validation Loss: 8.0646, Validation mIoU: 0.7596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30/110 Training: 100%|██████████| 112/112 [06:08<00:00,  3.29s/it, loss=85.4323]\n",
      "Epoch 30/110 Validation: 100%|██████████| 14/14 [00:41<00:00,  2.97s/it, loss=104.7291]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/110, Train Loss: 5.3630, Train mIoU: 0.8683, Validation Loss: 7.8403, Validation mIoU: 0.7345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31/110 Training: 100%|██████████| 112/112 [06:16<00:00,  3.37s/it, loss=81.7401]\n",
      "Epoch 31/110 Validation: 100%|██████████| 14/14 [00:39<00:00,  2.80s/it, loss=132.5495]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/110, Train Loss: 5.2835, Train mIoU: 0.8709, Validation Loss: 7.8547, Validation mIoU: 0.7773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32/110 Training: 100%|██████████| 112/112 [06:16<00:00,  3.36s/it, loss=81.6292] \n",
      "Epoch 32/110 Validation: 100%|██████████| 14/14 [00:45<00:00,  3.29s/it, loss=123.8131]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/110, Train Loss: 5.5809, Train mIoU: 0.8699, Validation Loss: 8.3859, Validation mIoU: 0.7514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33/110 Training: 100%|██████████| 112/112 [06:18<00:00,  3.38s/it, loss=96.2843] \n",
      "Epoch 33/110 Validation: 100%|██████████| 14/14 [00:42<00:00,  3.02s/it, loss=123.3301]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/110, Train Loss: 5.3337, Train mIoU: 0.8777, Validation Loss: 8.0973, Validation mIoU: 0.7641\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34/110 Training: 100%|██████████| 112/112 [06:08<00:00,  3.29s/it, loss=80.1332] \n",
      "Epoch 34/110 Validation: 100%|██████████| 14/14 [00:38<00:00,  2.77s/it, loss=145.1810]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/110, Train Loss: 5.3706, Train mIoU: 0.8795, Validation Loss: 8.2540, Validation mIoU: 0.7316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35/110 Training: 100%|██████████| 112/112 [06:12<00:00,  3.32s/it, loss=79.2056]\n",
      "Epoch 35/110 Validation: 100%|██████████| 14/14 [00:41<00:00,  2.93s/it, loss=90.5401] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/110, Train Loss: 5.3760, Train mIoU: 0.8645, Validation Loss: 7.8298, Validation mIoU: 0.7824\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36/110 Training: 100%|██████████| 112/112 [06:12<00:00,  3.32s/it, loss=83.2289]\n",
      "Epoch 36/110 Validation: 100%|██████████| 14/14 [00:40<00:00,  2.89s/it, loss=113.3196]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/110, Train Loss: 4.9911, Train mIoU: 0.8756, Validation Loss: 7.9152, Validation mIoU: 0.7302\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37/110 Training: 100%|██████████| 112/112 [06:19<00:00,  3.39s/it, loss=94.3741] \n",
      "Epoch 37/110 Validation: 100%|██████████| 14/14 [00:44<00:00,  3.16s/it, loss=124.9485]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/110, Train Loss: 4.9814, Train mIoU: 0.8717, Validation Loss: 8.1908, Validation mIoU: 0.7248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38/110 Training: 100%|██████████| 112/112 [06:15<00:00,  3.35s/it, loss=72.6202] \n",
      "Epoch 38/110 Validation: 100%|██████████| 14/14 [00:40<00:00,  2.92s/it, loss=117.0646]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/110, Train Loss: 5.1210, Train mIoU: 0.8597, Validation Loss: 7.8168, Validation mIoU: 0.7367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39/110 Training: 100%|██████████| 112/112 [06:13<00:00,  3.33s/it, loss=87.7326] \n",
      "Epoch 39/110 Validation: 100%|██████████| 14/14 [00:41<00:00,  2.98s/it, loss=143.1897]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/110, Train Loss: 5.0666, Train mIoU: 0.8498, Validation Loss: 8.4450, Validation mIoU: 0.7123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40/110 Training: 100%|██████████| 112/112 [06:12<00:00,  3.32s/it, loss=80.0509]\n",
      "Epoch 40/110 Validation: 100%|██████████| 14/14 [00:43<00:00,  3.10s/it, loss=145.0665]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/110, Train Loss: 4.9892, Train mIoU: 0.8669, Validation Loss: 8.3220, Validation mIoU: 0.7888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41/110 Training: 100%|██████████| 112/112 [06:17<00:00,  3.37s/it, loss=78.3698]\n",
      "Epoch 41/110 Validation: 100%|██████████| 14/14 [00:42<00:00,  3.07s/it, loss=208.1985]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/110, Train Loss: 4.9615, Train mIoU: 0.8798, Validation Loss: 8.2251, Validation mIoU: 0.6950\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 42/110 Training: 100%|██████████| 112/112 [06:21<00:00,  3.41s/it, loss=73.0255]\n",
      "Epoch 42/110 Validation: 100%|██████████| 14/14 [00:42<00:00,  3.04s/it, loss=112.1368]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/110, Train Loss: 5.1140, Train mIoU: 0.8599, Validation Loss: 7.9561, Validation mIoU: 0.7556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 43/110 Training: 100%|██████████| 112/112 [06:12<00:00,  3.33s/it, loss=91.2770]\n",
      "Epoch 43/110 Validation: 100%|██████████| 14/14 [00:42<00:00,  3.05s/it, loss=130.8797]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/110, Train Loss: 4.7186, Train mIoU: 0.8826, Validation Loss: 8.2719, Validation mIoU: 0.7659\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 44/110 Training: 100%|██████████| 112/112 [06:10<00:00,  3.31s/it, loss=69.2326]\n",
      "Epoch 44/110 Validation: 100%|██████████| 14/14 [00:41<00:00,  2.99s/it, loss=189.1159]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/110, Train Loss: 4.5593, Train mIoU: 0.8772, Validation Loss: 8.0593, Validation mIoU: 0.7429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 45/110 Training: 100%|██████████| 112/112 [06:17<00:00,  3.37s/it, loss=81.6108]\n",
      "Epoch 45/110 Validation: 100%|██████████| 14/14 [00:41<00:00,  2.95s/it, loss=110.7702]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/110, Train Loss: 4.4449, Train mIoU: 0.8863, Validation Loss: 8.1324, Validation mIoU: 0.7145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 46/110 Training: 100%|██████████| 112/112 [06:07<00:00,  3.28s/it, loss=74.3946]\n",
      "Epoch 46/110 Validation: 100%|██████████| 14/14 [00:35<00:00,  2.56s/it, loss=109.6624]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/110, Train Loss: 4.6429, Train mIoU: 0.8741, Validation Loss: 7.9114, Validation mIoU: 0.7933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 47/110 Training: 100%|██████████| 112/112 [06:05<00:00,  3.26s/it, loss=67.3759]\n",
      "Epoch 47/110 Validation: 100%|██████████| 14/14 [00:42<00:00,  3.07s/it, loss=96.8803] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/110, Train Loss: 4.5335, Train mIoU: 0.8829, Validation Loss: 7.7874, Validation mIoU: 0.7503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 48/110 Training: 100%|██████████| 112/112 [06:18<00:00,  3.38s/it, loss=71.0857]\n",
      "Epoch 48/110 Validation: 100%|██████████| 14/14 [00:40<00:00,  2.88s/it, loss=108.4149]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/110, Train Loss: 4.7876, Train mIoU: 0.8798, Validation Loss: 8.2846, Validation mIoU: 0.7375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 49/110 Training: 100%|██████████| 112/112 [06:13<00:00,  3.33s/it, loss=76.9127]\n",
      "Epoch 49/110 Validation: 100%|██████████| 14/14 [00:42<00:00,  3.01s/it, loss=187.3259]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/110, Train Loss: 4.4574, Train mIoU: 0.8821, Validation Loss: 8.0079, Validation mIoU: 0.7443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 50/110 Training: 100%|██████████| 112/112 [06:10<00:00,  3.31s/it, loss=67.6232]\n",
      "Epoch 50/110 Validation: 100%|██████████| 14/14 [00:39<00:00,  2.80s/it, loss=176.9978]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/110, Train Loss: 4.2267, Train mIoU: 0.8862, Validation Loss: 8.3417, Validation mIoU: 0.7605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 51/110 Training: 100%|██████████| 112/112 [06:19<00:00,  3.39s/it, loss=83.3491]\n",
      "Epoch 51/110 Validation: 100%|██████████| 14/14 [00:44<00:00,  3.16s/it, loss=99.2848] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51/110, Train Loss: 4.1729, Train mIoU: 0.8866, Validation Loss: 8.3512, Validation mIoU: 0.7797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 52/110 Training: 100%|██████████| 112/112 [06:17<00:00,  3.37s/it, loss=71.0529]\n",
      "Epoch 52/110 Validation: 100%|██████████| 14/14 [00:40<00:00,  2.93s/it, loss=119.8707]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52/110, Train Loss: 4.4247, Train mIoU: 0.8523, Validation Loss: 7.8449, Validation mIoU: 0.7845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 53/110 Training: 100%|██████████| 112/112 [06:21<00:00,  3.40s/it, loss=65.2648]\n",
      "Epoch 53/110 Validation: 100%|██████████| 14/14 [00:42<00:00,  3.01s/it, loss=145.8271]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/110, Train Loss: 4.2011, Train mIoU: 0.8731, Validation Loss: 7.8329, Validation mIoU: 0.8059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 54/110 Training: 100%|██████████| 112/112 [06:18<00:00,  3.38s/it, loss=80.8462]\n",
      "Epoch 54/110 Validation: 100%|██████████| 14/14 [00:39<00:00,  2.81s/it, loss=90.8396] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54/110, Train Loss: 4.1142, Train mIoU: 0.8858, Validation Loss: 7.7983, Validation mIoU: 0.7539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 55/110 Training: 100%|██████████| 112/112 [06:23<00:00,  3.43s/it, loss=76.8546]\n",
      "Epoch 55/110 Validation: 100%|██████████| 14/14 [00:41<00:00,  2.97s/it, loss=145.0527]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/110, Train Loss: 4.2444, Train mIoU: 0.8883, Validation Loss: 8.2718, Validation mIoU: 0.6532\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 56/110 Training: 100%|██████████| 112/112 [06:21<00:00,  3.41s/it, loss=74.6158] \n",
      "Epoch 56/110 Validation: 100%|██████████| 14/14 [00:39<00:00,  2.80s/it, loss=124.1848]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/110, Train Loss: 4.9492, Train mIoU: 0.8817, Validation Loss: 8.4248, Validation mIoU: 0.7481\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 57/110 Training: 100%|██████████| 112/112 [06:07<00:00,  3.28s/it, loss=75.7085]\n",
      "Epoch 57/110 Validation: 100%|██████████| 14/14 [00:43<00:00,  3.11s/it, loss=118.8639]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/110, Train Loss: 4.5461, Train mIoU: 0.8847, Validation Loss: 8.3558, Validation mIoU: 0.7695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 58/110 Training: 100%|██████████| 112/112 [06:11<00:00,  3.31s/it, loss=73.0761]\n",
      "Epoch 58/110 Validation: 100%|██████████| 14/14 [00:37<00:00,  2.67s/it, loss=174.2192]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/110, Train Loss: 4.2883, Train mIoU: 0.8871, Validation Loss: 8.6223, Validation mIoU: 0.7196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 59/110 Training: 100%|██████████| 112/112 [06:02<00:00,  3.23s/it, loss=77.3474]\n",
      "Epoch 59/110 Validation: 100%|██████████| 14/14 [00:37<00:00,  2.71s/it, loss=134.5484]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/110, Train Loss: 4.1710, Train mIoU: 0.8861, Validation Loss: 7.9430, Validation mIoU: 0.7000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 60/110 Training: 100%|██████████| 112/112 [06:08<00:00,  3.29s/it, loss=63.5938]\n",
      "Epoch 60/110 Validation: 100%|██████████| 14/14 [00:41<00:00,  2.98s/it, loss=120.1027]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60/110, Train Loss: 4.0198, Train mIoU: 0.8828, Validation Loss: 7.8530, Validation mIoU: 0.7261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 61/110 Training: 100%|██████████| 112/112 [06:07<00:00,  3.28s/it, loss=58.3019]\n",
      "Epoch 61/110 Validation: 100%|██████████| 14/14 [00:42<00:00,  3.04s/it, loss=118.4647]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/110, Train Loss: 4.0210, Train mIoU: 0.8632, Validation Loss: 8.2386, Validation mIoU: 0.6919\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 62/110 Training: 100%|██████████| 112/112 [06:06<00:00,  3.27s/it, loss=70.6514]\n",
      "Epoch 62/110 Validation: 100%|██████████| 14/14 [00:35<00:00,  2.54s/it, loss=142.8454]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/110, Train Loss: 3.8779, Train mIoU: 0.8777, Validation Loss: 7.9819, Validation mIoU: 0.7454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 63/110 Training: 100%|██████████| 112/112 [06:13<00:00,  3.34s/it, loss=63.6232]\n",
      "Epoch 63/110 Validation: 100%|██████████| 14/14 [00:40<00:00,  2.87s/it, loss=148.8664]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63/110, Train Loss: 3.7871, Train mIoU: 0.8908, Validation Loss: 8.0283, Validation mIoU: 0.7261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 64/110 Training: 100%|██████████| 112/112 [06:10<00:00,  3.31s/it, loss=78.5261]\n",
      "Epoch 64/110 Validation: 100%|██████████| 14/14 [00:43<00:00,  3.08s/it, loss=211.7089]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64/110, Train Loss: 3.9554, Train mIoU: 0.8901, Validation Loss: 10.7008, Validation mIoU: 0.7769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 65/110 Training: 100%|██████████| 112/112 [06:14<00:00,  3.35s/it, loss=66.3837]\n",
      "Epoch 65/110 Validation: 100%|██████████| 14/14 [00:40<00:00,  2.93s/it, loss=125.1017]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65/110, Train Loss: 4.6485, Train mIoU: 0.8486, Validation Loss: 9.2537, Validation mIoU: 0.7399\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 66/110 Training: 100%|██████████| 112/112 [06:16<00:00,  3.36s/it, loss=68.1784]\n",
      "Epoch 66/110 Validation: 100%|██████████| 14/14 [00:41<00:00,  2.96s/it, loss=121.4528]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66/110, Train Loss: 4.0988, Train mIoU: 0.8852, Validation Loss: 7.7685, Validation mIoU: 0.7677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 67/110 Training: 100%|██████████| 112/112 [06:10<00:00,  3.31s/it, loss=67.0510]\n",
      "Epoch 67/110 Validation: 100%|██████████| 14/14 [00:38<00:00,  2.78s/it, loss=129.2693]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67/110, Train Loss: 3.7981, Train mIoU: 0.8821, Validation Loss: 8.0081, Validation mIoU: 0.7714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 68/110 Training: 100%|██████████| 112/112 [06:12<00:00,  3.32s/it, loss=65.1566]\n",
      "Epoch 68/110 Validation: 100%|██████████| 14/14 [00:43<00:00,  3.08s/it, loss=99.8453] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68/110, Train Loss: 3.8212, Train mIoU: 0.8908, Validation Loss: 7.9622, Validation mIoU: 0.7271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 69/110 Training: 100%|██████████| 112/112 [06:14<00:00,  3.34s/it, loss=54.4329]\n",
      "Epoch 69/110 Validation: 100%|██████████| 14/14 [00:40<00:00,  2.92s/it, loss=133.5040]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69/110, Train Loss: 3.8773, Train mIoU: 0.8895, Validation Loss: 8.2349, Validation mIoU: 0.7798\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 70/110 Training: 100%|██████████| 112/112 [06:14<00:00,  3.34s/it, loss=69.4531]\n",
      "Epoch 70/110 Validation: 100%|██████████| 14/14 [00:41<00:00,  2.96s/it, loss=118.3763]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70/110, Train Loss: 3.8165, Train mIoU: 0.8715, Validation Loss: 8.0230, Validation mIoU: 0.6956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 71/110 Training: 100%|██████████| 112/112 [06:23<00:00,  3.42s/it, loss=63.8733]\n",
      "Epoch 71/110 Validation: 100%|██████████| 14/14 [00:48<00:00,  3.49s/it, loss=108.9589]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71/110, Train Loss: 3.7039, Train mIoU: 0.8919, Validation Loss: 8.0240, Validation mIoU: 0.7391\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 72/110 Training: 100%|██████████| 112/112 [06:14<00:00,  3.35s/it, loss=56.2297]\n",
      "Epoch 72/110 Validation: 100%|██████████| 14/14 [00:35<00:00,  2.53s/it, loss=97.7751] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72/110, Train Loss: 3.6425, Train mIoU: 0.8924, Validation Loss: 8.1175, Validation mIoU: 0.7382\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 73/110 Training: 100%|██████████| 112/112 [06:16<00:00,  3.36s/it, loss=56.9931]\n",
      "Epoch 73/110 Validation: 100%|██████████| 14/14 [00:42<00:00,  3.04s/it, loss=165.0127]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73/110, Train Loss: 3.5973, Train mIoU: 0.8924, Validation Loss: 8.4900, Validation mIoU: 0.7424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 74/110 Training: 100%|██████████| 112/112 [06:24<00:00,  3.43s/it, loss=61.7518]\n",
      "Epoch 74/110 Validation: 100%|██████████| 14/14 [00:39<00:00,  2.80s/it, loss=105.7981]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74/110, Train Loss: 3.5302, Train mIoU: 0.8919, Validation Loss: 8.5149, Validation mIoU: 0.7573\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 75/110 Training: 100%|██████████| 112/112 [05:59<00:00,  3.21s/it, loss=80.6331] \n",
      "Epoch 75/110 Validation: 100%|██████████| 14/14 [00:41<00:00,  2.98s/it, loss=133.6363]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75/110, Train Loss: 3.5555, Train mIoU: 0.8908, Validation Loss: 8.3698, Validation mIoU: 0.8183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 76/110 Training: 100%|██████████| 112/112 [06:13<00:00,  3.34s/it, loss=106.2054]\n",
      "Epoch 76/110 Validation: 100%|██████████| 14/14 [00:38<00:00,  2.78s/it, loss=160.1930]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76/110, Train Loss: 5.2057, Train mIoU: 0.8300, Validation Loss: 10.6319, Validation mIoU: 0.6630\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 77/110 Training: 100%|██████████| 112/112 [06:07<00:00,  3.28s/it, loss=62.4755]\n",
      "Epoch 77/110 Validation: 100%|██████████| 14/14 [00:39<00:00,  2.79s/it, loss=124.6865]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77/110, Train Loss: 4.9726, Train mIoU: 0.8506, Validation Loss: 8.3745, Validation mIoU: 0.7799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 78/110 Training: 100%|██████████| 112/112 [06:13<00:00,  3.34s/it, loss=94.2802]\n",
      "Epoch 78/110 Validation: 100%|██████████| 14/14 [00:43<00:00,  3.11s/it, loss=108.3571]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78/110, Train Loss: 3.9254, Train mIoU: 0.8825, Validation Loss: 8.1611, Validation mIoU: 0.8055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 79/110 Training: 100%|██████████| 112/112 [06:14<00:00,  3.34s/it, loss=54.4780]\n",
      "Epoch 79/110 Validation: 100%|██████████| 14/14 [00:40<00:00,  2.86s/it, loss=142.8563]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79/110, Train Loss: 3.9820, Train mIoU: 0.8802, Validation Loss: 8.3835, Validation mIoU: 0.7805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 80/110 Training: 100%|██████████| 112/112 [06:18<00:00,  3.38s/it, loss=70.4817]\n",
      "Epoch 80/110 Validation: 100%|██████████| 14/14 [00:43<00:00,  3.10s/it, loss=126.0212]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/110, Train Loss: 4.0326, Train mIoU: 0.8849, Validation Loss: 8.1446, Validation mIoU: 0.7753\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 81/110 Training: 100%|██████████| 112/112 [06:15<00:00,  3.35s/it, loss=57.3315]\n",
      "Epoch 81/110 Validation: 100%|██████████| 14/14 [00:41<00:00,  2.95s/it, loss=117.1318]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81/110, Train Loss: 3.6586, Train mIoU: 0.8890, Validation Loss: 8.0457, Validation mIoU: 0.7760\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 82/110 Training: 100%|██████████| 112/112 [06:21<00:00,  3.40s/it, loss=53.9091]\n",
      "Epoch 82/110 Validation: 100%|██████████| 14/14 [00:43<00:00,  3.12s/it, loss=118.0915]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82/110, Train Loss: 3.7974, Train mIoU: 0.8876, Validation Loss: 8.6246, Validation mIoU: 0.7782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 83/110 Training: 100%|██████████| 112/112 [06:10<00:00,  3.31s/it, loss=54.1264]\n",
      "Epoch 83/110 Validation: 100%|██████████| 14/14 [00:37<00:00,  2.69s/it, loss=171.2393]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83/110, Train Loss: 3.5809, Train mIoU: 0.8903, Validation Loss: 8.2591, Validation mIoU: 0.7418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 84/110 Training: 100%|██████████| 112/112 [06:10<00:00,  3.31s/it, loss=53.5306]\n",
      "Epoch 84/110 Validation: 100%|██████████| 14/14 [00:40<00:00,  2.88s/it, loss=118.7275]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84/110, Train Loss: 3.4214, Train mIoU: 0.8936, Validation Loss: 8.0625, Validation mIoU: 0.7751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 85/110 Training: 100%|██████████| 112/112 [06:15<00:00,  3.35s/it, loss=59.1661]\n",
      "Epoch 85/110 Validation: 100%|██████████| 14/14 [00:42<00:00,  3.06s/it, loss=88.3193] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85/110, Train Loss: 3.3760, Train mIoU: 0.8939, Validation Loss: 8.4784, Validation mIoU: 0.7499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 86/110 Training: 100%|██████████| 112/112 [06:11<00:00,  3.32s/it, loss=52.4387]\n",
      "Epoch 86/110 Validation: 100%|██████████| 14/14 [00:41<00:00,  2.95s/it, loss=124.3296]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 86/110, Train Loss: 3.4562, Train mIoU: 0.8906, Validation Loss: 8.2824, Validation mIoU: 0.7147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 87/110 Training: 100%|██████████| 112/112 [06:01<00:00,  3.23s/it, loss=51.7282]\n",
      "Epoch 87/110 Validation: 100%|██████████| 14/14 [00:36<00:00,  2.63s/it, loss=114.1225]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 87/110, Train Loss: 4.1122, Train mIoU: 0.8570, Validation Loss: 8.3840, Validation mIoU: 0.7817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 88/110 Training: 100%|██████████| 112/112 [06:16<00:00,  3.36s/it, loss=67.0899]\n",
      "Epoch 88/110 Validation: 100%|██████████| 14/14 [00:40<00:00,  2.86s/it, loss=137.6998]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 88/110, Train Loss: 3.5305, Train mIoU: 0.8920, Validation Loss: 8.7052, Validation mIoU: 0.7417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 89/110 Training: 100%|██████████| 112/112 [06:05<00:00,  3.26s/it, loss=48.3001]\n",
      "Epoch 89/110 Validation: 100%|██████████| 14/14 [00:39<00:00,  2.83s/it, loss=136.2785]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89/110, Train Loss: 3.5370, Train mIoU: 0.8883, Validation Loss: 7.9023, Validation mIoU: 0.7197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 90/110 Training: 100%|██████████| 112/112 [06:01<00:00,  3.23s/it, loss=52.5167]\n",
      "Epoch 90/110 Validation: 100%|██████████| 14/14 [00:41<00:00,  2.98s/it, loss=123.4686]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90/110, Train Loss: 3.3700, Train mIoU: 0.8929, Validation Loss: 8.6390, Validation mIoU: 0.7443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 91/110 Training: 100%|██████████| 112/112 [06:07<00:00,  3.29s/it, loss=53.8160]\n",
      "Epoch 91/110 Validation: 100%|██████████| 14/14 [00:41<00:00,  2.98s/it, loss=148.2362]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 91/110, Train Loss: 3.5438, Train mIoU: 0.8623, Validation Loss: 7.9256, Validation mIoU: 0.7569\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 92/110 Training: 100%|██████████| 112/112 [05:58<00:00,  3.20s/it, loss=55.1922]\n",
      "Epoch 92/110 Validation: 100%|██████████| 14/14 [00:39<00:00,  2.80s/it, loss=125.8430]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 92/110, Train Loss: 3.4041, Train mIoU: 0.8908, Validation Loss: 8.3716, Validation mIoU: 0.7486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 93/110 Training: 100%|██████████| 112/112 [05:59<00:00,  3.21s/it, loss=53.0960]\n",
      "Epoch 93/110 Validation: 100%|██████████| 14/14 [00:41<00:00,  2.96s/it, loss=174.0335]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 93/110, Train Loss: 3.6003, Train mIoU: 0.8845, Validation Loss: 8.0612, Validation mIoU: 0.7260\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 94/110 Training: 100%|██████████| 112/112 [06:02<00:00,  3.24s/it, loss=53.1766]\n",
      "Epoch 94/110 Validation: 100%|██████████| 14/14 [00:42<00:00,  3.03s/it, loss=97.6434] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 94/110, Train Loss: 3.2547, Train mIoU: 0.8924, Validation Loss: 7.9374, Validation mIoU: 0.7427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 95/110 Training: 100%|██████████| 112/112 [06:09<00:00,  3.30s/it, loss=76.6273]\n",
      "Epoch 95/110 Validation: 100%|██████████| 14/14 [00:41<00:00,  2.98s/it, loss=177.8506]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95/110, Train Loss: 3.3622, Train mIoU: 0.8833, Validation Loss: 8.4240, Validation mIoU: 0.7834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 96/110 Training: 100%|██████████| 112/112 [06:06<00:00,  3.27s/it, loss=46.6619]\n",
      "Epoch 96/110 Validation: 100%|██████████| 14/14 [00:44<00:00,  3.15s/it, loss=147.7455]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 96/110, Train Loss: 3.3115, Train mIoU: 0.8823, Validation Loss: 8.0758, Validation mIoU: 0.7915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 97/110 Training: 100%|██████████| 112/112 [06:02<00:00,  3.24s/it, loss=50.5556]\n",
      "Epoch 97/110 Validation: 100%|██████████| 14/14 [00:36<00:00,  2.62s/it, loss=113.9885]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97/110, Train Loss: 3.3966, Train mIoU: 0.8872, Validation Loss: 7.8672, Validation mIoU: 0.8101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 98/110 Training: 100%|██████████| 112/112 [06:07<00:00,  3.28s/it, loss=46.5159]\n",
      "Epoch 98/110 Validation: 100%|██████████| 14/14 [00:42<00:00,  3.06s/it, loss=110.4448]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 98/110, Train Loss: 3.4330, Train mIoU: 0.8896, Validation Loss: 7.9986, Validation mIoU: 0.7775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 99/110 Training: 100%|██████████| 112/112 [06:02<00:00,  3.24s/it, loss=51.7440]\n",
      "Epoch 99/110 Validation: 100%|██████████| 14/14 [00:31<00:00,  2.25s/it, loss=140.0768]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99/110, Train Loss: 3.6676, Train mIoU: 0.8883, Validation Loss: 7.8084, Validation mIoU: 0.7952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 100/110 Training: 100%|██████████| 112/112 [06:03<00:00,  3.25s/it, loss=61.2571]\n",
      "Epoch 100/110 Validation: 100%|██████████| 14/14 [00:41<00:00,  2.98s/it, loss=162.0311]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/110, Train Loss: 3.2296, Train mIoU: 0.8943, Validation Loss: 8.3263, Validation mIoU: 0.7775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 101/110 Training: 100%|██████████| 112/112 [06:10<00:00,  3.31s/it, loss=63.0106]\n",
      "Epoch 101/110 Validation: 100%|██████████| 14/14 [00:39<00:00,  2.85s/it, loss=121.1318]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 101/110, Train Loss: 3.1669, Train mIoU: 0.8949, Validation Loss: 8.4986, Validation mIoU: 0.7572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 102/110 Training: 100%|██████████| 112/112 [05:53<00:00,  3.16s/it, loss=51.8454]\n",
      "Epoch 102/110 Validation: 100%|██████████| 14/14 [00:41<00:00,  2.98s/it, loss=105.6758]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 102/110, Train Loss: 3.1536, Train mIoU: 0.8951, Validation Loss: 7.9503, Validation mIoU: 0.8129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 103/110 Training: 100%|██████████| 112/112 [06:02<00:00,  3.24s/it, loss=43.6428]\n",
      "Epoch 103/110 Validation: 100%|██████████| 14/14 [00:39<00:00,  2.85s/it, loss=117.4209]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 103/110, Train Loss: 3.0725, Train mIoU: 0.8946, Validation Loss: 8.2998, Validation mIoU: 0.7804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 104/110 Training: 100%|██████████| 112/112 [06:02<00:00,  3.23s/it, loss=44.7161]\n",
      "Epoch 104/110 Validation: 100%|██████████| 14/14 [00:38<00:00,  2.75s/it, loss=148.5388]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 104/110, Train Loss: 3.0775, Train mIoU: 0.8955, Validation Loss: 8.7601, Validation mIoU: 0.7790\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 105/110 Training: 100%|██████████| 112/112 [06:08<00:00,  3.29s/it, loss=45.9061]\n",
      "Epoch 105/110 Validation: 100%|██████████| 14/14 [00:43<00:00,  3.12s/it, loss=95.9401] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 105/110, Train Loss: 3.0534, Train mIoU: 0.8956, Validation Loss: 8.2323, Validation mIoU: 0.7695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 106/110 Training: 100%|██████████| 112/112 [06:09<00:00,  3.30s/it, loss=46.2696]\n",
      "Epoch 106/110 Validation: 100%|██████████| 14/14 [00:40<00:00,  2.87s/it, loss=124.8912]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 106/110, Train Loss: 3.0542, Train mIoU: 0.8960, Validation Loss: 8.2351, Validation mIoU: 0.7475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 107/110 Training: 100%|██████████| 112/112 [06:09<00:00,  3.30s/it, loss=49.5898]\n",
      "Epoch 107/110 Validation: 100%|██████████| 14/14 [00:41<00:00,  2.96s/it, loss=123.9954]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 107/110, Train Loss: 3.1767, Train mIoU: 0.8908, Validation Loss: 8.6936, Validation mIoU: 0.7602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 108/110 Training: 100%|██████████| 112/112 [05:53<00:00,  3.16s/it, loss=55.0713]\n",
      "Epoch 108/110 Validation: 100%|██████████| 14/14 [00:36<00:00,  2.62s/it, loss=124.2938]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 108/110, Train Loss: 3.5431, Train mIoU: 0.8806, Validation Loss: 8.6622, Validation mIoU: 0.7661\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 109/110 Training: 100%|██████████| 112/112 [05:53<00:00,  3.16s/it, loss=44.6753]\n",
      "Epoch 109/110 Validation: 100%|██████████| 14/14 [00:37<00:00,  2.68s/it, loss=97.6525] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 109/110, Train Loss: 3.1937, Train mIoU: 0.8936, Validation Loss: 8.1484, Validation mIoU: 0.7677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 110/110 Training: 100%|██████████| 112/112 [05:48<00:00,  3.11s/it, loss=52.4550]\n",
      "Epoch 110/110 Validation: 100%|██████████| 14/14 [00:41<00:00,  3.00s/it, loss=124.5382]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 110/110, Train Loss: 3.1319, Train mIoU: 0.8934, Validation Loss: 8.2447, Validation mIoU: 0.7220\n"
     ]
    }
   ],
   "source": [
    "# To avoid making stupid errors\n",
    "CURR_TASK = \"B\"\n",
    "\n",
    "# For storing the model\n",
    "best_val_metric = -np.inf\n",
    "\n",
    "# Move model to device\n",
    "model.to(device)\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    model.train()\n",
    "    train_running_loss = 0.0\n",
    "    val_running_loss = 0.0\n",
    "\n",
    "    # Set up tqdm for the training loop\n",
    "    train_loader = tqdm(\n",
    "        dataloaders[CURR_TASK][\"train\"], desc=f\"Epoch {epoch + 1}/{NUM_EPOCHS} Training\"\n",
    "    )\n",
    "\n",
    "    for batch in train_loader:\n",
    "        # Move everything to the device\n",
    "        batch[\"pixel_values\"] = batch[\"pixel_values\"].to(device)\n",
    "        batch[\"pixel_mask\"] = batch[\"pixel_mask\"].to(device)\n",
    "        batch[\"mask_labels\"] = [entry.to(device) for entry in batch[\"mask_labels\"]]\n",
    "        batch[\"class_labels\"] = [entry.to(device) for entry in batch[\"class_labels\"]]\n",
    "\n",
    "        # Compute output and loss\n",
    "        outputs = model(**batch)\n",
    "\n",
    "        loss = outputs.loss\n",
    "\n",
    "        # Compute gradient and perform step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Record losses\n",
    "        current_loss = loss.item() * batch[\"pixel_values\"].size(0)\n",
    "        train_running_loss += current_loss\n",
    "        train_loader.set_postfix(loss=f\"{current_loss:.4f}\")\n",
    "\n",
    "        # Extract and compute metrics\n",
    "        pred_maps, masks = m2f_extract_pred_maps_and_masks(\n",
    "            batch, outputs, m2f_preprocessor_B\n",
    "        )\n",
    "        metric.add_batch(references=masks, predictions=pred_maps)\n",
    "\n",
    "    # After compute the batches that were added are deleted\n",
    "    mean_train_iou = metric.compute(\n",
    "        num_labels=NUM_CLASSES, ignore_index=BG_VALUE_255, reduce_labels=False\n",
    "    )[\"mean_iou\"]\n",
    "\n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    val_loader = tqdm(\n",
    "        dataloaders[CURR_TASK][\"val\"], desc=f\"Epoch {epoch + 1}/{NUM_EPOCHS} Validation\"\n",
    "    )\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            # Move everything to the device\n",
    "            batch[\"pixel_values\"] = batch[\"pixel_values\"].to(device)\n",
    "            batch[\"pixel_mask\"] = batch[\"pixel_mask\"].to(device)\n",
    "            batch[\"mask_labels\"] = [entry.to(device) for entry in batch[\"mask_labels\"]]\n",
    "            batch[\"class_labels\"] = [\n",
    "                entry.to(device) for entry in batch[\"class_labels\"]\n",
    "            ]\n",
    "            # Compute output and loss\n",
    "            outputs = model(**batch)\n",
    "\n",
    "            loss = outputs.loss\n",
    "            # Record losses\n",
    "            current_loss = loss.item() * batch[\"pixel_values\"].size(0)\n",
    "            val_running_loss += current_loss\n",
    "            val_loader.set_postfix(loss=f\"{current_loss:.4f}\")\n",
    "\n",
    "            # Extract and compute metrics\n",
    "            pred_maps, masks = m2f_extract_pred_maps_and_masks(\n",
    "                batch, outputs, m2f_preprocessor_B\n",
    "            )\n",
    "            metric.add_batch(references=masks, predictions=pred_maps)\n",
    "\n",
    "    # After compute the batches that were added are deleted\n",
    "    mean_val_iou = metric.compute(\n",
    "        num_labels=NUM_CLASSES, ignore_index=BG_VALUE_255, reduce_labels=False\n",
    "    )[\"mean_iou\"]\n",
    "\n",
    "    epoch_train_loss = train_running_loss / len(dataloaders[CURR_TASK][\"train\"].dataset)\n",
    "    epoch_val_loss = val_running_loss / len(dataloaders[CURR_TASK][\"val\"].dataset)\n",
    "\n",
    "    writer.add_scalar(f\"Loss/train_{base_model_name}_{CURR_TASK}\", epoch_train_loss, epoch + 1)\n",
    "    writer.add_scalar(f\"Loss/val_{base_model_name}_{CURR_TASK}\", epoch_val_loss, epoch + 1)\n",
    "    writer.add_scalar(f\"mIoU/train_{base_model_name}_{CURR_TASK}\", mean_train_iou, epoch + 1)\n",
    "    writer.add_scalar(f\"mIoU/val_{base_model_name}_{CURR_TASK}\", mean_val_iou, epoch + 1)\n",
    "\n",
    "    wandb.log({\n",
    "        f\"Loss/train_{CURR_TASK}\": epoch_train_loss,\n",
    "        f\"Loss/val_{CURR_TASK}\": epoch_val_loss,\n",
    "        f\"mIoU/train_{CURR_TASK}\": mean_train_iou,\n",
    "        f\"mIoU/val_{CURR_TASK}\": mean_val_iou\n",
    "    })\n",
    "\n",
    "    if mean_val_iou > best_val_metric:\n",
    "        best_val_metric = mean_val_iou\n",
    "        model.save_pretrained(f\"{best_model_dir}{CURR_TASK}/\")\n",
    "\n",
    "    tqdm.write(\n",
    "        f\"Epoch {epoch + 1}/{NUM_EPOCHS}, Train Loss: {epoch_train_loss:.4f}, Train mIoU: {mean_train_iou:.4f}, Validation Loss: {epoch_val_loss:.4f}, Validation mIoU: {mean_val_iou:.4f}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Test results on A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-09T18:08:43.736252Z",
     "iopub.status.busy": "2024-05-09T18:08:43.735662Z",
     "iopub.status.idle": "2024-05-09T18:08:47.893951Z",
     "shell.execute_reply": "2024-05-09T18:08:47.890020Z",
     "shell.execute_reply.started": "2024-05-09T18:08:43.736201Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load best model and evaluate on test\n",
    "model = Mask2FormerForUniversalSegmentation.from_pretrained(f\"{best_model_dir}{CURR_TASK}/\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-09T18:08:47.903452Z",
     "iopub.status.busy": "2024-05-09T18:08:47.902689Z",
     "iopub.status.idle": "2024-05-09T18:11:24.870315Z",
     "shell.execute_reply": "2024-05-09T18:11:24.859371Z",
     "shell.execute_reply.started": "2024-05-09T18:08:47.903419Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test loop: 100%|██████████| 73/73 [02:23<00:00,  1.97s/it, loss=158.3683]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 15.9287, Test mIoU: 0.7058\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "test_running_loss = 0\n",
    "test_loader = tqdm(dataloaders[CURR_TASK][\"test\"], desc=\"Test loop\")\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        # Move everything to the device\n",
    "        batch[\"pixel_values\"] = batch[\"pixel_values\"].to(device)\n",
    "        batch[\"pixel_mask\"] = batch[\"pixel_mask\"].to(device)\n",
    "        batch[\"mask_labels\"] = [entry.to(device) for entry in batch[\"mask_labels\"]]\n",
    "        batch[\"class_labels\"] = [entry.to(device) for entry in batch[\"class_labels\"]]\n",
    "        # Compute output and loss\n",
    "        outputs = model(**batch)\n",
    "\n",
    "        loss = outputs.loss\n",
    "        # Record losses\n",
    "        current_loss = loss.item() * batch[\"pixel_values\"].size(0)\n",
    "        test_running_loss += current_loss\n",
    "        test_loader.set_postfix(loss=f\"{current_loss:.4f}\")\n",
    "\n",
    "        # Extract and compute metrics\n",
    "        pred_maps, masks = m2f_extract_pred_maps_and_masks(\n",
    "            batch, outputs, m2f_preprocessor_A\n",
    "        )\n",
    "        metric.add_batch(references=masks, predictions=pred_maps)\n",
    "        \n",
    "# After compute the batches that were added are deleted\n",
    "test_metrics_A = metric.compute(\n",
    "    num_labels=NUM_CLASSES, ignore_index=BG_VALUE_255, reduce_labels=False\n",
    ")\n",
    "mean_test_iou = test_metrics_A[\"mean_iou\"]\n",
    "final_test_loss = test_running_loss / len(dataloaders[CURR_TASK][\"test\"].dataset)\n",
    "wandb.log({\n",
    "    f\"Loss/test_{CURR_TASK}\": final_test_loss,\n",
    "    f\"mIoU/test_{CURR_TASK}\": mean_test_iou\n",
    "})\n",
    "print(f\"Test Loss: {final_test_loss:.4f}, Test mIoU: {mean_test_iou:.4f}\")\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Now train on B and forget A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "NUM_EPOCHS = 200\n",
    "LEARNING_RATE = 1e-4\n",
    "LR_MULTIPLIER = 0.1\n",
    "BACKBONE_LR = LEARNING_RATE * LR_MULTIPLIER\n",
    "WEIGHT_DECAY = 0.05\n",
    "encoder_params = [\n",
    "    param\n",
    "    for name, param in model.named_parameters()\n",
    "    if name.startswith(\"model.pixel_level_module.encoder\")\n",
    "]\n",
    "decoder_params = [\n",
    "    param\n",
    "    for name, param in model.named_parameters()\n",
    "    if name.startswith(\"model.pixel_level_module.decoder\")\n",
    "]\n",
    "transformer_params = [\n",
    "    param\n",
    "    for name, param in model.named_parameters()\n",
    "    if name.startswith(\"model.transformer_module\")\n",
    "]\n",
    "optimizer = optim.AdamW(\n",
    "    [\n",
    "        {\"params\": encoder_params, \"lr\": BACKBONE_LR},\n",
    "        {\"params\": decoder_params},\n",
    "        {\"params\": transformer_params},\n",
    "    ],\n",
    "    lr=LEARNING_RATE,\n",
    "    weight_decay=WEIGHT_DECAY,\n",
    ")\n",
    "\n",
    "scheduler = optim.lr_scheduler.PolynomialLR(\n",
    "    optimizer, total_iters=NUM_EPOCHS, power=0.9\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mge85ket\u001b[0m (\u001b[33mcontinual-learning-tum\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# WandB for team usage !!!!\n",
    "\n",
    "wandb.login() # use this one if a different person is going to run the notebook\n",
    "#wandb.login(relogin=False) # if the same person in the last run is going to run the notebook again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/notebooks/continual-learning/wandb/run-20240514_075000-sz26zgxo</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/continual-learning-tum/M2F_original/runs/sz26zgxo' target=\"_blank\">M2F-Swin-Tiny-Naive-Forgetting</a></strong> to <a href='https://wandb.ai/continual-learning-tum/M2F_original' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/continual-learning-tum/M2F_original' target=\"_blank\">https://wandb.ai/continual-learning-tum/M2F_original</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/continual-learning-tum/M2F_original/runs/sz26zgxo' target=\"_blank\">https://wandb.ai/continual-learning-tum/M2F_original/runs/sz26zgxo</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.init(\n",
    "    project=\"M2F_original\",\n",
    "    config={\n",
    "        \"learning_rate\": LEARNING_RATE,\n",
    "        \"learning_rate_multiplier\": LR_MULTIPLIER,\n",
    "        \"backbone_learning_rate\": BACKBONE_LR,\n",
    "        \"learning_rate_scheduler\": scheduler.__class__.__name__,\n",
    "        \"optimizer\": optimizer.__class__.__name__,\n",
    "        \"backbone\": SWIN_BACKBONE,\n",
    "        \"m2f_preprocessor\": m2f_preprocessor_B.__dict__,\n",
    "        \"m2f_model_config\": model.config\n",
    "    },\n",
    "    name=\"M2F-Swin-Tiny-Naive-Forgetting\",\n",
    "    notes=\"M2F with tiny Swin backbone pretrained on ImageNet-1K. \\\n",
    "        Scenario: Pretrained on A, Train on B, Test forgetting on A\"\n",
    ")\n",
    "# Tensorboard logging\n",
    "writer = SummaryWriter(log_dir=out_dir + \"runs\")\n",
    "# Model checkpointing\n",
    "model_name = \"m2f_swin_backbone_naive_forgetting\"\n",
    "model_dir = out_dir + \"models/\"\n",
    "if not os.path.exists(model_dir):\n",
    "    print(\"Store weights in: \", model_dir)\n",
    "    os.makedirs(model_dir)\n",
    "\n",
    "best_model_dir = model_dir + f\"{model_name}/best_model/\"\n",
    "if not os.path.exists(best_model_dir):\n",
    "    print(\"Store best model weights in: \", best_model_dir)\n",
    "    os.makedirs(best_model_dir)\n",
    "final_model_dir = model_dir + f\"{model_name}/final_model/\"\n",
    "if not os.path.exists(final_model_dir):\n",
    "    print(\"Store final model weights in: \", final_model_dir)\n",
    "    os.makedirs(final_model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the preprocessor\n",
    "m2f_preprocessor_B.save_pretrained(model_dir + model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-09T18:11:25.351858Z",
     "iopub.status.busy": "2024-05-09T18:11:25.350010Z",
     "iopub.status.idle": "2024-05-09T19:13:20.730571Z",
     "shell.execute_reply": "2024-05-09T19:13:20.728154Z",
     "shell.execute_reply.started": "2024-05-09T18:11:25.351721Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5 Training: 100%|██████████| 225/225 [10:28<00:00,  2.79s/it, loss=140.3550]\n",
      "Epoch 1/5 Validation: 100%|██████████| 28/28 [00:53<00:00,  1.92s/it, loss=147.4061]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Train Loss: 21.2275, Train mIoU: 0.4917, Validation Loss: 17.3837, Validation mIoU: 0.6450\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5 Training: 100%|██████████| 225/225 [09:51<00:00,  2.63s/it, loss=88.4616] \n",
      "Epoch 2/5 Validation: 100%|██████████| 28/28 [00:51<00:00,  1.84s/it, loss=90.7679] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/5, Train Loss: 16.5085, Train mIoU: 0.6278, Validation Loss: 11.5713, Validation mIoU: 0.7547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5 Training: 100%|██████████| 225/225 [11:22<00:00,  3.03s/it, loss=71.2189] \n",
      "Epoch 3/5 Validation: 100%|██████████| 28/28 [00:49<00:00,  1.78s/it, loss=75.3303] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/5, Train Loss: 11.1197, Train mIoU: 0.7375, Validation Loss: 9.1890, Validation mIoU: 0.7599\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5 Training: 100%|██████████| 225/225 [12:14<00:00,  3.26s/it, loss=74.6497] \n",
      "Epoch 4/5 Validation: 100%|██████████| 28/28 [00:49<00:00,  1.77s/it, loss=58.7313] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/5, Train Loss: 9.1472, Train mIoU: 0.7742, Validation Loss: 8.5610, Validation mIoU: 0.7252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5 Training: 100%|██████████| 225/225 [11:06<00:00,  2.96s/it, loss=80.4140] \n",
      "Epoch 5/5 Validation: 100%|██████████| 28/28 [00:51<00:00,  1.85s/it, loss=83.1679] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/5, Train Loss: 8.9787, Train mIoU: 0.7828, Validation Loss: 10.4601, Validation mIoU: 0.7588\n"
     ]
    }
   ],
   "source": [
    "# To avoid making stupid errors\n",
    "CURR_TASK = \"B\"\n",
    "\n",
    "# For storing the model\n",
    "best_val_metric = -np.inf\n",
    "\n",
    "# Move model to device\n",
    "model.to(device)\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    model.train()\n",
    "    train_running_loss = 0.0\n",
    "    val_running_loss = 0.0\n",
    "\n",
    "    # Set up tqdm for the training loop\n",
    "    train_loader = tqdm(\n",
    "        dataloaders[CURR_TASK][\"train\"], desc=f\"Epoch {epoch + 1}/{NUM_EPOCHS} Training\"\n",
    "    )\n",
    "\n",
    "    for batch in train_loader:\n",
    "        # Move everything to the device\n",
    "        batch[\"pixel_values\"] = batch[\"pixel_values\"].to(device)\n",
    "        batch[\"pixel_mask\"] = batch[\"pixel_mask\"].to(device)\n",
    "        batch[\"mask_labels\"] = [entry.to(device) for entry in batch[\"mask_labels\"]]\n",
    "        batch[\"class_labels\"] = [entry.to(device) for entry in batch[\"class_labels\"]]\n",
    "\n",
    "        # Compute output and loss\n",
    "        outputs = model(**batch)\n",
    "\n",
    "        loss = outputs.loss\n",
    "\n",
    "        # Compute gradient and perform step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Record losses\n",
    "        current_loss = loss.item() * batch[\"pixel_values\"].size(0)\n",
    "        train_running_loss += current_loss\n",
    "        train_loader.set_postfix(loss=f\"{current_loss:.4f}\")\n",
    "\n",
    "        # Extract and compute metrics\n",
    "        pred_maps, masks = m2f_extract_pred_maps_and_masks(\n",
    "            batch, outputs, m2f_preprocessor_B\n",
    "        )\n",
    "        metric.add_batch(references=masks, predictions=pred_maps)\n",
    "\n",
    "    # After compute the batches that were added are deleted\n",
    "    mean_train_iou = metric.compute(\n",
    "        num_labels=NUM_CLASSES, ignore_index=BG_VALUE_255, reduce_labels=False\n",
    "    )[\"mean_iou\"]\n",
    "\n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    val_loader = tqdm(\n",
    "        dataloaders[CURR_TASK][\"val\"], desc=f\"Epoch {epoch + 1}/{NUM_EPOCHS} Validation\"\n",
    "    )\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            # Move everything to the device\n",
    "            batch[\"pixel_values\"] = batch[\"pixel_values\"].to(device)\n",
    "            batch[\"pixel_mask\"] = batch[\"pixel_mask\"].to(device)\n",
    "            batch[\"mask_labels\"] = [entry.to(device) for entry in batch[\"mask_labels\"]]\n",
    "            batch[\"class_labels\"] = [\n",
    "                entry.to(device) for entry in batch[\"class_labels\"]\n",
    "            ]\n",
    "            # Compute output and loss\n",
    "            outputs = model(**batch)\n",
    "\n",
    "            loss = outputs.loss\n",
    "            # Record losses\n",
    "            current_loss = loss.item() * batch[\"pixel_values\"].size(0)\n",
    "            val_running_loss += current_loss\n",
    "            val_loader.set_postfix(loss=f\"{current_loss:.4f}\")\n",
    "\n",
    "            # Extract and compute metrics\n",
    "            pred_maps, masks = m2f_extract_pred_maps_and_masks(\n",
    "                batch, outputs, m2f_preprocessor_B\n",
    "            )\n",
    "            metric.add_batch(references=masks, predictions=pred_maps)\n",
    "\n",
    "    # After compute the batches that were added are deleted\n",
    "    mean_val_iou = metric.compute(\n",
    "        num_labels=NUM_CLASSES, ignore_index=BG_VALUE_255, reduce_labels=False\n",
    "    )[\"mean_iou\"]\n",
    "\n",
    "    epoch_train_loss = train_running_loss / len(dataloaders[CURR_TASK][\"train\"].dataset)\n",
    "    epoch_val_loss = val_running_loss / len(dataloaders[CURR_TASK][\"val\"].dataset)\n",
    "\n",
    "    writer.add_scalar(f\"Loss/train_{model_name}_{CURR_TASK}\", epoch_train_loss, epoch + 1)\n",
    "    writer.add_scalar(f\"Loss/val_{model_name}_{CURR_TASK}\", epoch_val_loss, epoch + 1)\n",
    "    writer.add_scalar(f\"mIoU/train_{model_name}_{CURR_TASK}\", mean_train_iou, epoch + 1)\n",
    "    writer.add_scalar(f\"mIoU/val_{model_name}_{CURR_TASK}\", mean_val_iou, epoch + 1)\n",
    "\n",
    "    wandb.log({\n",
    "        f\"Loss/train_{CURR_TASK}\": epoch_train_loss,\n",
    "        f\"Loss/val_{CURR_TASK}\": epoch_val_loss,\n",
    "        f\"mIoU/train_{CURR_TASK}\": mean_train_iou,\n",
    "        f\"mIoU/val_{CURR_TASK}\": mean_val_iou\n",
    "    })\n",
    "\n",
    "    if mean_val_iou > best_val_metric:\n",
    "        best_val_metric = mean_val_iou\n",
    "        model.save_pretrained(f\"{best_model_dir}{CURR_TASK}/\")\n",
    "\n",
    "    tqdm.write(\n",
    "        f\"Epoch {epoch + 1}/{NUM_EPOCHS}, Train Loss: {epoch_train_loss:.4f}, Train mIoU: {mean_train_iou:.4f}, Validation Loss: {epoch_val_loss:.4f}, Validation mIoU: {mean_val_iou:.4f}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Test results on B first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load best model and evaluate on test\n",
    "model = Mask2FormerForUniversalSegmentation.from_pretrained(f\"{best_model_dir}{CURR_TASK}/\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test loop: 100%|██████████| 14/14 [00:43<00:00,  3.12s/it, loss=129.5613]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 8.7328, Test mIoU: 0.7895\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "test_running_loss = 0\n",
    "test_loader = tqdm(dataloaders[CURR_TASK][\"test\"], desc=\"Test loop\")\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        # Move everything to the device\n",
    "        batch[\"pixel_values\"] = batch[\"pixel_values\"].to(device)\n",
    "        batch[\"pixel_mask\"] = batch[\"pixel_mask\"].to(device)\n",
    "        batch[\"mask_labels\"] = [entry.to(device) for entry in batch[\"mask_labels\"]]\n",
    "        batch[\"class_labels\"] = [entry.to(device) for entry in batch[\"class_labels\"]]\n",
    "        # Compute output and loss\n",
    "        outputs = model(**batch)\n",
    "\n",
    "        loss = outputs.loss\n",
    "        # Record losses\n",
    "        current_loss = loss.item() * batch[\"pixel_values\"].size(0)\n",
    "        test_running_loss += current_loss\n",
    "        test_loader.set_postfix(loss=f\"{current_loss:.4f}\")\n",
    "\n",
    "        # Extract and compute metrics\n",
    "        pred_maps, masks = m2f_extract_pred_maps_and_masks(\n",
    "            batch, outputs, m2f_preprocessor_B\n",
    "        )\n",
    "        metric.add_batch(references=masks, predictions=pred_maps)\n",
    "\n",
    "# After compute the batches that were added are deleted\n",
    "test_metrics_B = metric.compute(\n",
    "    num_labels=NUM_CLASSES, ignore_index=BG_VALUE_255, reduce_labels=False\n",
    ")\n",
    "mean_test_iou = test_metrics_B[\"mean_iou\"]\n",
    "final_test_loss = test_running_loss / len(dataloaders[CURR_TASK][\"test\"].dataset)\n",
    "wandb.log({\n",
    "    f\"Loss/test_{CURR_TASK}\": final_test_loss,\n",
    "    f\"mIoU/test_{CURR_TASK}\": mean_test_iou\n",
    "})\n",
    "print(f\"Test Loss: {final_test_loss:.4f}, Test mIoU: {mean_test_iou:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Loss/test_B</td><td>▁</td></tr><tr><td>Loss/train_B</td><td>█▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Loss/val_B</td><td>█▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>mIoU/test_B</td><td>▁</td></tr><tr><td>mIoU/train_B</td><td>▁▃▅▆▇▇▇████████████████████▇████████████</td></tr><tr><td>mIoU/val_B</td><td>▁▄▅▇█▇▇█████▇▇█▇▇▇█▇▇▇▇▇▇▇▇▇████▇▇█████▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Loss/test_B</td><td>8.73283</td></tr><tr><td>Loss/train_B</td><td>3.13194</td></tr><tr><td>Loss/val_B</td><td>8.24469</td></tr><tr><td>mIoU/test_B</td><td>0.78951</td></tr><tr><td>mIoU/train_B</td><td>0.89339</td></tr><tr><td>mIoU/val_B</td><td>0.72203</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">M2F-Swin-Tiny-Train_Cataract1K</strong> at: <a href='https://wandb.ai/continual-learning-tum/M2F_original/runs/vfh7zerl' target=\"_blank\">https://wandb.ai/continual-learning-tum/M2F_original/runs/vfh7zerl</a><br/> View project at: <a href='https://wandb.ai/continual-learning-tum/M2F_original' target=\"_blank\">https://wandb.ai/continual-learning-tum/M2F_original</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240517_120558-vfh7zerl/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Test results on A after training on B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-09T19:14:20.161687Z",
     "iopub.status.busy": "2024-05-09T19:14:20.160508Z",
     "iopub.status.idle": "2024-05-09T19:16:31.936806Z",
     "shell.execute_reply": "2024-05-09T19:16:31.934655Z",
     "shell.execute_reply.started": "2024-05-09T19:14:20.161660Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test loop: 100%|██████████| 73/73 [02:05<00:00,  1.73s/it, loss=279.5755]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 38.9396, Test mIoU: 0.4669\n"
     ]
    }
   ],
   "source": [
    "# To avoid making stupid errors\n",
    "CURR_TASK = \"A\"\n",
    "\n",
    "model.eval()\n",
    "test_running_loss = 0\n",
    "test_loader = tqdm(dataloaders[CURR_TASK][\"test\"], desc=\"Test loop\")\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        # Move everything to the device\n",
    "        batch[\"pixel_values\"] = batch[\"pixel_values\"].to(device)\n",
    "        batch[\"pixel_mask\"] = batch[\"pixel_mask\"].to(device)\n",
    "        batch[\"mask_labels\"] = [entry.to(device) for entry in batch[\"mask_labels\"]]\n",
    "        batch[\"class_labels\"] = [entry.to(device) for entry in batch[\"class_labels\"]]\n",
    "        # Compute output and loss\n",
    "        outputs = model(**batch)\n",
    "\n",
    "        loss = outputs.loss\n",
    "        # Record losses\n",
    "        current_loss = loss.item() * batch[\"pixel_values\"].size(0)\n",
    "        test_running_loss += current_loss\n",
    "        test_loader.set_postfix(loss=f\"{current_loss:.4f}\")\n",
    "\n",
    "        # Extract and compute metrics\n",
    "        pred_maps, masks = m2f_extract_pred_maps_and_masks(\n",
    "            batch, outputs, m2f_preprocessor_A\n",
    "        )\n",
    "        metric.add_batch(references=masks, predictions=pred_maps)\n",
    "        \n",
    "# After compute the batches that were added are deleted\n",
    "test_metrics_forgetting_A = metric.compute(\n",
    "    num_labels=NUM_CLASSES, ignore_index=BG_VALUE_255, reduce_labels=False\n",
    ")\n",
    "mean_test_iou = test_metrics_forgetting_A[\"mean_iou\"]\n",
    "final_test_loss = test_running_loss / len(dataloaders[CURR_TASK][\"test\"].dataset)\n",
    "wandb.log({\n",
    "    f\"Loss/test_naive_forgetting_{CURR_TASK}\": final_test_loss,\n",
    "    f\"mIoU/test_naive_forgetting_{CURR_TASK}\": mean_test_iou\n",
    "})\n",
    "print(f\"Test Loss: {final_test_loss:.4f}, Test mIoU: {mean_test_iou:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect overall mIoU\n",
    "mIoU_A = test_metrics_A[\"mean_iou\"]\n",
    "mIoU_forgetting_A = test_metrics_forgetting_A[\"mean_iou\"]\n",
    "mIoU_B = test_metrics_B[\"mean_iou\"]\n",
    "\n",
    "# Collect per category mIoU\n",
    "per_category_mIoU_A = np.array(test_metrics_A[\"per_category_iou\"])\n",
    "per_category_mIoU_forgetting_A = np.array(test_metrics_forgetting_A[\"per_category_iou\"])\n",
    "per_category_mIoU_B = np.array(test_metrics_forgetting_A[\"per_category_iou\"])\n",
    "\n",
    "# Average learning accuracies (mIoUs)\n",
    "avg_learning_acc = (mIoU_A + mIoU_B) / 2\n",
    "per_category_avg_learning_acc = (per_category_mIoU_A + per_category_mIoU_B) / 2\n",
    "\n",
    "# Forgetting\n",
    "total_forgetting = mIoU_A - mIoU_forgetting_A\n",
    "per_category_forgetting = (per_category_mIoU_A - per_category_mIoU_forgetting_A)\n",
    "\n",
    "# Export evaluation metrics to WandB\n",
    "wandb.log({\n",
    "    \"eval/avg_learning_acc\": avg_learning_acc,\n",
    "    \"eval/per_category_avg_learning_acc\": per_category_avg_learning_acc,\n",
    "    \"eval/total_forgetting\": total_forgetting,\n",
    "    \"eval/per_category_forgetting\": per_category_forgetting\n",
    "})\n",
    "print(\"**** Overall mIoU ****\")\n",
    "print(f\"mIoU on task A: {mIoU_A}\")\n",
    "print(f\"mIoU on task B: {mIoU_B}\")\n",
    "print(f\"mIoU on task A after training on B: {mIoU_forgetting_A}\")\n",
    "\n",
    "print(\"\\n**** Per category mIoU ****\")\n",
    "print(f\"Per category mIoU on task A: {per_category_mIoU_A}\")\n",
    "print(f\"Per category mIoU on task B: {per_category_mIoU_B}\")\n",
    "print(f\"Per category mIoU on task A after training on B: {per_category_mIoU_forgetting_A}\")\n",
    "\n",
    "print(\"\\n**** Average learning accuracies ****\")\n",
    "print(f\"Average learning acc.: {avg_learning_acc}\")\n",
    "print(f\"Per category Average learning acc.: {per_category_avg_learning_acc}\")\n",
    "\n",
    "print(\"\\n**** Forgetting ****\")\n",
    "print(f\"Total forgetting: {total_forgetting}\")\n",
    "print(f\"Per category forgetting: {per_category_forgetting}\")\n",
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
