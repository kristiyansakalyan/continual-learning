{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-09T14:23:14.996451Z",
     "iopub.status.busy": "2024-05-09T14:23:14.995894Z",
     "iopub.status.idle": "2024-05-09T14:23:15.067303Z",
     "shell.execute_reply": "2024-05-09T14:23:15.066032Z",
     "shell.execute_reply.started": "2024-05-09T14:23:14.996331Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "from utils.common import (\n",
    "    set_seed,\n",
    "    m2f_dataset_collate,\n",
    "    m2f_extract_pred_maps_and_masks,\n",
    ")\n",
    "from utils.dataset_utils import (\n",
    "    get_cadisv2_dataset,\n",
    "    get_cataract1k_dataset,\n",
    "    ZEISS_CATEGORIES,\n",
    ")\n",
    "from utils.medical_datasets import Mask2FormerDataset\n",
    "from transformers import (\n",
    "    Mask2FormerForUniversalSegmentation,\n",
    "    SwinModel,\n",
    "    SwinConfig,\n",
    "    Mask2FormerConfig,\n",
    "    AutoImageProcessor,\n",
    "    Mask2FormerImageProcessor\n",
    ")\n",
    "from torch.utils.data import DataLoader\n",
    "import evaluate\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import numpy as np\n",
    "from dotenv import load_dotenv\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-09T14:24:04.867273Z",
     "iopub.status.busy": "2024-05-09T14:24:04.866693Z",
     "iopub.status.idle": "2024-05-09T14:24:04.956655Z",
     "shell.execute_reply": "2024-05-09T14:24:04.955494Z",
     "shell.execute_reply.started": "2024-05-09T14:24:04.866954Z"
    }
   },
   "outputs": [],
   "source": [
    "set_seed(42) # seed everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-09T14:24:04.972892Z",
     "iopub.status.busy": "2024-05-09T14:24:04.972634Z",
     "iopub.status.idle": "2024-05-09T14:24:26.785066Z",
     "shell.execute_reply": "2024-05-09T14:24:26.783460Z",
     "shell.execute_reply.started": "2024-05-09T14:24:04.972871Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/notebooks/venv/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not Matched: hidden_states_norms.stage1.weight != layernorm.weight\n",
      "Not Matched: hidden_states_norms.stage1.bias != layernorm.bias\n"
     ]
    }
   ],
   "source": [
    "NUM_CLASSES = len(ZEISS_CATEGORIES) - 3  # Remove class incremental\n",
    "SWIN_BACKBONE = \"microsoft/swin-large-patch4-window12-384\"\n",
    "\n",
    "# Download pretrained swin model\n",
    "swin_model = SwinModel.from_pretrained(\n",
    "    SWIN_BACKBONE, out_features=[\"stage1\", \"stage2\", \"stage3\", \"stage4\"]\n",
    ")\n",
    "swin_config = SwinConfig.from_pretrained(\n",
    "    SWIN_BACKBONE, out_features=[\"stage1\", \"stage2\", \"stage3\", \"stage4\"]\n",
    ")\n",
    "\n",
    "# Create Mask2Former configuration based on Swin's configuration\n",
    "mask2former_config = Mask2FormerConfig(\n",
    "    backbone_config=swin_config, num_labels=NUM_CLASSES #, ignore_value=BG_VALUE\n",
    ")\n",
    "\n",
    "# Create the Mask2Former model with this configuration\n",
    "model = Mask2FormerForUniversalSegmentation(mask2former_config)\n",
    "\n",
    "# Reuse pretrained parameters\n",
    "for swin_param, m2f_param in zip(\n",
    "    swin_model.named_parameters(),\n",
    "    model.model.pixel_level_module.encoder.named_parameters(),\n",
    "):\n",
    "    m2f_param_name = f\"model.pixel_level_module.encoder.{m2f_param[0]}\"\n",
    "\n",
    "    if swin_param[0] == m2f_param[0]:\n",
    "        model.state_dict()[m2f_param_name].copy_(swin_param[1])\n",
    "        continue\n",
    "\n",
    "    print(f\"Not Matched: {m2f_param[0]} != {swin_param[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-09T14:24:26.790763Z",
     "iopub.status.busy": "2024-05-09T14:24:26.790343Z",
     "iopub.status.idle": "2024-05-09T14:24:30.676210Z",
     "shell.execute_reply": "2024-05-09T14:24:30.674148Z",
     "shell.execute_reply.started": "2024-05-09T14:24:26.790763Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/notebooks/venv/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Could not find image processor class in the image processor config or the model config. Loading based on pattern matching with the model's feature extractor configuration. Please open a PR/issue to update `preprocessor_config.json` to use `image_processor_type` instead of `feature_extractor_type`. This warning will be removed in v4.40.\n"
     ]
    }
   ],
   "source": [
    "# Domain incremental datasets\n",
    "train_cadis_ds, val_cadis_ds, test_cadis_ds = get_cadisv2_dataset(\n",
    "    \"../../storage/data/CaDISv2\", domain_incremental=True\n",
    ")\n",
    "train_cataract_ds, val_cataract_ds, test_cataract_ds = get_cataract1k_dataset(\n",
    "    \"../../storage/data/cataract-1k\", domain_incremental=True\n",
    ")\n",
    "\n",
    "# First case: CADIS + CATARACT at the same time\n",
    "merged_train_ds = torch.utils.data.ConcatDataset([train_cataract_ds, train_cadis_ds])\n",
    "merged_val_ds = torch.utils.data.ConcatDataset([val_cataract_ds, val_cadis_ds])\n",
    "merged_test_ds = torch.utils.data.ConcatDataset([test_cataract_ds, test_cadis_ds])\n",
    "\n",
    "pixel_mean_A,pixel_std_A=pixel_mean_std(train_cadis_ds)\n",
    "pixel_mean_B,pixel_std_B=pixel_mean_std(merged_train_ds)\n",
    "\n",
    "# Define preprocessor\n",
    "swin_processor = AutoImageProcessor.from_pretrained(SWIN_BACKBONE)\n",
    "m2f_preprocessor_A = Mask2FormerImageProcessor(\n",
    "    reduce_labels=True,\n",
    "    ignore_index=255,\n",
    "    do_resize=False,\n",
    "    do_rescale=True,\n",
    "    do_normalize=True,\n",
    "    #size=#swin_processor.size,\n",
    "    image_std=pixel_std_A, \n",
    "    image_mean=pixel_mean_A \n",
    ")\n",
    "\n",
    "m2f_preprocessor_B = Mask2FormerImageProcessor(\n",
    "    reduce_labels=True,\n",
    "    ignore_index=255,\n",
    "    do_resize=False,\n",
    "    do_rescale=True,\n",
    "    do_normalize=True,\n",
    "    #size=#swin_processor.size,\n",
    "    image_std=pixel_std_B,\n",
    "    image_mean=pixel_mean_B\n",
    ")\n",
    "\n",
    "# Create M2F Dataset\n",
    "train_ds = Mask2FormerDataset(merged_train_ds, m2f_preprocessor_B)\n",
    "val_ds = Mask2FormerDataset(merged_val_ds, m2f_preprocessor_B)\n",
    "test_ds = Mask2FormerDataset(merged_test_ds, m2f_preprocessor_B)\n",
    "\n",
    "# Define dataloader params\n",
    "N_WORKERS = 1\n",
    "BATCH_SIZE = 2\n",
    "SHUFFLE = True\n",
    "DROP_LAST = True\n",
    "\n",
    "# Define dataloader\n",
    "train_merged_loader = DataLoader(\n",
    "    train_ds,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=SHUFFLE,\n",
    "    num_workers=N_WORKERS,\n",
    "    drop_last=DROP_LAST,\n",
    "    pin_memory=True,\n",
    "    collate_fn=m2f_dataset_collate,\n",
    ")\n",
    "val_merged_loader = DataLoader(\n",
    "    val_ds,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=SHUFFLE,\n",
    "    num_workers=N_WORKERS,\n",
    "    drop_last=DROP_LAST,\n",
    "    pin_memory=True,\n",
    "    collate_fn=m2f_dataset_collate,\n",
    ")\n",
    "test_merged_loader = DataLoader(\n",
    "    test_ds,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=SHUFFLE,\n",
    "    num_workers=N_WORKERS,\n",
    "    drop_last=DROP_LAST,\n",
    "    pin_memory=True,\n",
    "    collate_fn=m2f_dataset_collate,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-09T14:24:30.683310Z",
     "iopub.status.busy": "2024-05-09T14:24:30.682868Z",
     "iopub.status.idle": "2024-05-09T14:24:37.925488Z",
     "shell.execute_reply": "2024-05-09T14:24:37.917814Z",
     "shell.execute_reply.started": "2024-05-09T14:24:30.683278Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Check if CUDA is available, otherwise use CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-09T11:18:33.241482Z",
     "iopub.status.busy": "2024-05-09T11:18:33.241199Z",
     "iopub.status.idle": "2024-05-09T11:18:33.306708Z",
     "shell.execute_reply": "2024-05-09T11:18:33.305853Z",
     "shell.execute_reply.started": "2024-05-09T11:18:33.241470Z"
    }
   },
   "outputs": [],
   "source": [
    "# Sanity check :)\n",
    "#\n",
    "#for batch in tqdm(train_merged_loader):\n",
    "#    batch[\"pixel_values\"] = batch[\"pixel_values\"].to(device)\n",
    "#    batch[\"pixel_mask\"] = batch[\"pixel_mask\"].to(device)\n",
    "#    batch[\"mask_labels\"] = [entry.to(device) for entry in batch[\"mask_labels\"]]\n",
    "#    batch[\"class_labels\"å] = [entry.to(device) for entry in batch[\"class_labels\"]]\n",
    "#\n",
    "#for batch in tqdm(val_merged_loader):\n",
    "#    batch[\"pixel_values\"] = batch[\"pixel_values\"].to(device)\n",
    "#    batch[\"pixel_mask\"] = batch[\"pixel_mask\"].to(device)\n",
    "#    batch[\"mask_labels\"] = [entry.to(device) for entry in batch[\"mask_labels\"]]\n",
    "#    batch[\"class_labels\"] = [entry.to(device) for entry in batch[\"class_labels\"]]\n",
    "#  \n",
    "#for batch in tqdm(test_merged_loader):\n",
    "#    batch[\"pixel_values\"] = batch[\"pixel_values\"].to(device)\n",
    "#    batch[\"pixel_mask\"] = batch[\"pixel_mask\"].to(device)\n",
    "#    batch[\"mask_labels\"] = [entry.to(device) for entry in batch[\"mask_labels\"]]\n",
    "#    batch[\"class_labels\"] = [entry.to(device) for entry in batch[\"class_labels\"]]\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-09T14:24:37.936699Z",
     "iopub.status.busy": "2024-05-09T14:24:37.936273Z",
     "iopub.status.idle": "2024-05-09T14:24:38.403515Z",
     "shell.execute_reply": "2024-05-09T14:24:38.402046Z",
     "shell.execute_reply.started": "2024-05-09T14:24:37.936656Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading builder script: 100%|██████████| 12.9k/12.9k [00:00<00:00, 25.4MB/s]\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "NUM_EPOCHS = 20\n",
    "LEARNING_RATE = 1e-4\n",
    "LR_MULTIPLIER = 0.1\n",
    "BACKBONE_LR = LEARNING_RATE * LR_MULTIPLIER\n",
    "WEIGHT_DECAY = 0.5\n",
    "# dice = Dice(average='micro')\n",
    "\n",
    "# lambda_CE=5.0\n",
    "# lambda_dice=5.0\n",
    "metric = evaluate.load(\"mean_iou\")\n",
    "encoder_params = [\n",
    "    param\n",
    "    for name, param in model.named_parameters()\n",
    "    if name.startswith(\"model.pixel_level_module.encoder\")\n",
    "]\n",
    "decoder_params = [\n",
    "    param\n",
    "    for name, param in model.named_parameters()\n",
    "    if name.startswith(\"model.pixel_level_module.decoder\")\n",
    "]\n",
    "transformer_params = [\n",
    "    param\n",
    "    for name, param in model.named_parameters()\n",
    "    if name.startswith(\"model.transformer_module\")\n",
    "]\n",
    "optimizer = optim.AdamW(\n",
    "    [\n",
    "        {\"params\": encoder_params, \"lr\": BACKBONE_LR},\n",
    "        {\"params\": decoder_params},\n",
    "        {\"params\": transformer_params},\n",
    "    ],\n",
    "    lr=LEARNING_RATE,\n",
    "    weight_decay=WEIGHT_DECAY,\n",
    ")\n",
    "\n",
    "scheduler = optim.lr_scheduler.PolynomialLR(\n",
    "    optimizer, total_iters=NUM_EPOCHS, power=0.9\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WandB for team usage !!!!\n",
    "\n",
    "wandb.login() # use this one if a different person is going to run the notebook\n",
    "#wandb.login(relogin=False) # if the same person in the last run is going to run the notebook again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-09T14:24:38.406429Z",
     "iopub.status.busy": "2024-05-09T14:24:38.405381Z",
     "iopub.status.idle": "2024-05-09T14:24:47.210914Z",
     "shell.execute_reply": "2024-05-09T14:24:47.210026Z",
     "shell.execute_reply.started": "2024-05-09T14:24:38.405850Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mkristiyan-sakalyan\u001b[0m (\u001b[33mkristiyan-sakalyan-tum\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/notebooks/continual-learning/wandb/run-20240509_142445-jdb6kw3e</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/kristiyan-sakalyan-tum/continual-learning/runs/jdb6kw3e' target=\"_blank\">M2F-Swin-Large-Merged</a></strong> to <a href='https://wandb.ai/kristiyan-sakalyan-tum/continual-learning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/kristiyan-sakalyan-tum/continual-learning' target=\"_blank\">https://wandb.ai/kristiyan-sakalyan-tum/continual-learning</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/kristiyan-sakalyan-tum/continual-learning/runs/jdb6kw3e' target=\"_blank\">https://wandb.ai/kristiyan-sakalyan-tum/continual-learning/runs/jdb6kw3e</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/kristiyan-sakalyan-tum/continual-learning/runs/jdb6kw3e?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7f88209500b0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(\n",
    "    project=\"M2F_original\",\n",
    "    config={\n",
    "        \"learning_rate\": LEARNING_RATE,\n",
    "        \"learning_rate_multiplier\": LR_MULTIPLIER,\n",
    "        \"backbone_learning_rate\": BACKBONE_LR,\n",
    "        \"learning_rate_scheduler\": scheduler.__class__.__name__,\n",
    "        \"optimizer\": optimizer.__class__.__name__,\n",
    "        \"backbone\": SWIN_BACKBONE,\n",
    "        \"m2f_preprocessor\": m2f_preprocessor.__dict__,\n",
    "        \"m2f_model_config\": model.config,\n",
    "        \"num_epochs\": NUM_EPOCHS\n",
    "    },\n",
    "    name=\"M2F-Swin-Large-Merged\",\n",
    "    notes=\"M2F with large Swin backbone pretrained on ImageNet-1K. \\\n",
    "        Scenario: Train, Validate and Test on A and B at the same\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-09T14:24:47.213155Z",
     "iopub.status.busy": "2024-05-09T14:24:47.212178Z",
     "iopub.status.idle": "2024-05-09T14:25:03.368169Z",
     "shell.execute_reply": "2024-05-09T14:25:03.366512Z",
     "shell.execute_reply.started": "2024-05-09T14:24:47.213111Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-1c80317fa3b1799d\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-1c80317fa3b1799d\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Tensorboard setup\n",
    "out_dir=\"outputs/\"\n",
    "if not os.path.exists(out_dir):\n",
    "    os.makedirs(out_dir)\n",
    "if not os.path.exists(out_dir+\"runs\"):\n",
    "    os.makedirs(out_dir+\"runs\")\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir outputs/runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-09T14:25:03.370538Z",
     "iopub.status.busy": "2024-05-09T14:25:03.369778Z",
     "iopub.status.idle": "2024-05-09T14:25:03.508449Z",
     "shell.execute_reply": "2024-05-09T14:25:03.507163Z",
     "shell.execute_reply.started": "2024-05-09T14:25:03.370159Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Tensorboard logging\n",
    "writer = SummaryWriter(log_dir=out_dir + \"runs\")\n",
    "\n",
    "# Model checkpointing\n",
    "model_name = \"m2f_swin_backbone\"\n",
    "model_dir = out_dir + \"models/\"\n",
    "if not os.path.exists(model_dir):\n",
    "    print(\"Store weights in: \", model_dir)\n",
    "    os.makedirs(model_dir)\n",
    "\n",
    "best_model_dir = model_dir + f\"{model_name}/best_models/\"\n",
    "if not os.path.exists(model_dir):\n",
    "    print(\"Store best model weights in: \", best_model_dir)\n",
    "    os.makedirs(best_model_dir)\n",
    "final_model_dir = model_dir + f\"{model_name}/final_model/\"\n",
    "if not os.path.exists(model_dir):\n",
    "    print(\"Store final model weights in: \", final_model_dir)\n",
    "    os.makedirs(final_model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-09T11:18:52.353530Z",
     "iopub.status.busy": "2024-05-09T11:18:52.352939Z",
     "iopub.status.idle": "2024-05-09T11:18:52.448278Z",
     "shell.execute_reply": "2024-05-09T11:18:52.446631Z",
     "shell.execute_reply.started": "2024-05-09T11:18:52.353433Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['outputs/models/m2f_swin_backbone/preprocessor_config.json']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the preprocessor\n",
    "m2f_preprocessor.save_pretrained(model_dir + model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-09T11:18:52.451117Z",
     "iopub.status.busy": "2024-05-09T11:18:52.450220Z",
     "iopub.status.idle": "2024-05-09T11:18:52.572705Z",
     "shell.execute_reply": "2024-05-09T11:18:52.569664Z",
     "shell.execute_reply.started": "2024-05-09T11:18:52.451117Z"
    }
   },
   "outputs": [],
   "source": [
    "#!rm -r outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-09T11:18:52.574616Z",
     "iopub.status.busy": "2024-05-09T11:18:52.574121Z",
     "iopub.status.idle": "2024-05-09T11:18:53.773546Z",
     "shell.execute_reply": "2024-05-09T11:18:53.772239Z",
     "shell.execute_reply.started": "2024-05-09T11:18:52.574582Z"
    }
   },
   "outputs": [],
   "source": [
    "!CUDA_LAUNCH_BLOCKING=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-09T11:18:53.775991Z",
     "iopub.status.busy": "2024-05-09T11:18:53.775602Z",
     "iopub.status.idle": "2024-05-09T13:53:39.946505Z",
     "shell.execute_reply": "2024-05-09T13:53:39.924669Z",
     "shell.execute_reply.started": "2024-05-09T11:18:53.775953Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/20 Training: 100%|██████████| 669/669 [55:28<00:00,  4.98s/it, loss=127.2057] \n",
      "Epoch 1/20 Validation: 100%|██████████| 94/94 [02:19<00:00,  1.48s/it, loss=115.7609]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, Train Loss: 36.5734, Train mIoU: 0.1242, Validation Loss: 17.1656, Validation mIoU: 0.2255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/20 Training: 100%|██████████| 669/669 [26:20<00:00,  2.36s/it, loss=118.0872]\n",
      "Epoch 2/20 Validation: 100%|██████████| 94/94 [02:28<00:00,  1.58s/it, loss=150.3683]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/20, Train Loss: 14.8691, Train mIoU: 0.1979, Validation Loss: 13.7972, Validation mIoU: 0.2754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/20 Training: 100%|██████████| 669/669 [26:54<00:00,  2.41s/it, loss=89.7419] \n",
      "Epoch 3/20 Validation: 100%|██████████| 94/94 [02:22<00:00,  1.52s/it, loss=77.9847] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/20, Train Loss: 11.9255, Train mIoU: 0.2336, Validation Loss: 12.6721, Validation mIoU: 0.4001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/20 Training: 100%|██████████| 669/669 [27:05<00:00,  2.43s/it, loss=85.6525] \n",
      "Epoch 4/20 Validation: 100%|██████████| 94/94 [02:25<00:00,  1.55s/it, loss=80.5599] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/20, Train Loss: 10.8787, Train mIoU: 0.2644, Validation Loss: 11.4897, Validation mIoU: 0.4380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/20 Training:   0%|          | 1/669 [00:10<1:54:01, 10.24s/it, loss=88.2779]\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# For storing the model\n",
    "best_val_metric = -np.inf\n",
    "\n",
    "# Move model to device\n",
    "model.to(device)\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    model.train()\n",
    "    train_running_loss = 0.0\n",
    "    val_running_loss = 0.0\n",
    "\n",
    "    # Set up tqdm for the training loop\n",
    "    train_loader = tqdm(\n",
    "        train_merged_loader, desc=f\"Epoch {epoch + 1}/{NUM_EPOCHS} Training\"\n",
    "    )\n",
    "\n",
    "    for batch in train_loader:\n",
    "        # Move everything to the device\n",
    "        batch[\"pixel_values\"] = batch[\"pixel_values\"].to(device)\n",
    "        batch[\"pixel_mask\"] = batch[\"pixel_mask\"].to(device)\n",
    "        batch[\"mask_labels\"] = [entry.to(device) for entry in batch[\"mask_labels\"]]\n",
    "        batch[\"class_labels\"] = [entry.to(device) for entry in batch[\"class_labels\"]]\n",
    "\n",
    "        # Compute output and loss\n",
    "        outputs = model(**batch)\n",
    "\n",
    "        loss = outputs.loss\n",
    "\n",
    "        # Compute gradient and perform step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Record losses\n",
    "        current_loss = loss.item() * batch[\"pixel_values\"].size(0)\n",
    "        train_running_loss += current_loss\n",
    "        train_loader.set_postfix(loss=f\"{current_loss:.4f}\")\n",
    "\n",
    "        # Extract and compute metrics\n",
    "        pred_maps, masks = m2f_extract_pred_maps_and_masks(\n",
    "            batch, outputs, m2f_preprocessor\n",
    "        )\n",
    "        metric.add_batch(references=masks, predictions=pred_maps)\n",
    "\n",
    "    # After compute the batches that were added are deleted\n",
    "    mean_train_iou = metric.compute(\n",
    "        num_labels=NUM_CLASSES, ignore_index=255, reduce_labels=False\n",
    "    )[\"mean_iou\"]\n",
    "\n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    val_loader = tqdm(\n",
    "        val_merged_loader, desc=f\"Epoch {epoch + 1}/{NUM_EPOCHS} Validation\"\n",
    "    )\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            # Move everything to the device\n",
    "            batch[\"pixel_values\"] = batch[\"pixel_values\"].to(device)\n",
    "            batch[\"pixel_mask\"] = batch[\"pixel_mask\"].to(device)\n",
    "            batch[\"mask_labels\"] = [entry.to(device) for entry in batch[\"mask_labels\"]]\n",
    "            batch[\"class_labels\"] = [\n",
    "                entry.to(device) for entry in batch[\"class_labels\"]\n",
    "            ]\n",
    "            # Compute output and loss\n",
    "            outputs = model(**batch)\n",
    "\n",
    "            loss = outputs.loss\n",
    "            # Record losses\n",
    "            current_loss = loss.item() * batch[\"pixel_values\"].size(0)\n",
    "            val_running_loss += current_loss\n",
    "            val_loader.set_postfix(loss=f\"{current_loss:.4f}\")\n",
    "\n",
    "            # Extract and compute metrics\n",
    "            pred_maps, masks = m2f_extract_pred_maps_and_masks(\n",
    "                batch, outputs, m2f_preprocessor\n",
    "            )\n",
    "            metric.add_batch(references=masks, predictions=pred_maps)\n",
    "\n",
    "    # After compute the batches that were added are deleted\n",
    "    mean_val_iou = metric.compute(\n",
    "        num_labels=NUM_CLASSES, ignore_index=255, reduce_labels=False\n",
    "    )[\"mean_iou\"]\n",
    "\n",
    "    epoch_train_loss = train_running_loss / len(train_merged_loader.dataset)\n",
    "    epoch_val_loss = val_running_loss / len(val_merged_loader.dataset)\n",
    "\n",
    "    writer.add_scalar(f\"Loss/train_{model_name}\", epoch_train_loss, epoch + 1)\n",
    "    writer.add_scalar(f\"Loss/val_{model_name}\", epoch_val_loss, epoch + 1)\n",
    "    writer.add_scalar(f\"mIoU/train_{model_name}\", mean_train_iou, epoch + 1)\n",
    "    writer.add_scalar(f\"mIoU/val_{model_name}\", mean_val_iou, epoch + 1)\n",
    "\n",
    "    wandb.log({\n",
    "        \"Loss/train\": epoch_train_loss,\n",
    "        \"Loss/val\": epoch_val_loss,\n",
    "        \"mIoU/train\": mean_train_iou,\n",
    "        \"mIoU/val\": mean_val_iou\n",
    "    })\n",
    "\n",
    "    if mean_val_iou > best_val_metric:\n",
    "        best_val_metric = mean_val_iou\n",
    "        model.save_pretrained(best_model_dir)\n",
    "\n",
    "    tqdm.write(\n",
    "        f\"Epoch {epoch + 1}/{NUM_EPOCHS}, Train Loss: {epoch_train_loss:.4f}, Train mIoU: {mean_train_iou:.4f}, Validation Loss: {epoch_val_loss:.4f}, Validation mIoU: {mean_val_iou:.4f}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-09T14:25:10.105385Z",
     "iopub.status.busy": "2024-05-09T14:25:10.104922Z",
     "iopub.status.idle": "2024-05-09T14:25:21.274031Z",
     "shell.execute_reply": "2024-05-09T14:25:21.271800Z",
     "shell.execute_reply.started": "2024-05-09T14:25:10.105351Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load best model and evaluate on test\n",
    "model = Mask2FormerForUniversalSegmentation.from_pretrained(best_model_dir).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-09T14:25:26.805102Z",
     "iopub.status.busy": "2024-05-09T14:25:26.804723Z",
     "iopub.status.idle": "2024-05-09T14:34:04.508744Z",
     "shell.execute_reply": "2024-05-09T14:34:04.506593Z",
     "shell.execute_reply.started": "2024-05-09T14:25:26.805077Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test loop: 100%|██████████| 406/406 [08:31<00:00,  1.26s/it, loss=21.9266] \n",
      "/root/.cache/huggingface/modules/evaluate_modules/metrics/evaluate-metric--mean_iou/9e450724f21f05592bfb0255fe2fa576df8171fa060d11121d8aecfff0db80d0/mean_iou.py:260: RuntimeWarning: invalid value encountered in divide\n",
      "  acc = total_area_intersect / total_area_label\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 13.6117, Test mIoU: {'mean_iou': 0.6957735810689049, 'mean_accuracy': 0.8476651174943084, 'overall_accuracy': 0.9544364853220599, 'per_category_iou': array([0.        , 0.89021496, 0.63482789, 0.55386392, 0.55942563,\n",
      "       0.7503169 , 0.78523856, 0.73548494, 0.888148  , 0.93037863,\n",
      "       0.92560997]), 'per_category_accuracy': array([       nan, 0.92747735, 0.72603455, 0.78361411, 0.60952089,\n",
      "       0.80568001, 0.84142026, 0.90333456, 0.95398366, 0.96638072,\n",
      "       0.95920505])}\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "test_running_loss = 0\n",
    "test_loader = tqdm(test_merged_loader, desc=\"Test loop\")\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        # Move everything to the device\n",
    "        batch[\"pixel_values\"] = batch[\"pixel_values\"].to(device)\n",
    "        batch[\"pixel_mask\"] = batch[\"pixel_mask\"].to(device)\n",
    "        batch[\"mask_labels\"] = [entry.to(device) for entry in batch[\"mask_labels\"]]\n",
    "        batch[\"class_labels\"] = [entry.to(device) for entry in batch[\"class_labels\"]]\n",
    "        # Compute output and loss\n",
    "        outputs = model(**batch)\n",
    "\n",
    "        loss = outputs.loss\n",
    "        # Record losses\n",
    "        current_loss = loss.item() * batch[\"pixel_values\"].size(0)\n",
    "        test_running_loss += current_loss\n",
    "        test_loader.set_postfix(loss=f\"{current_loss:.4f}\")\n",
    "\n",
    "        # Extract and compute metrics\n",
    "        pred_maps, masks = m2f_extract_pred_maps_and_masks(\n",
    "            batch, outputs, m2f_preprocessor\n",
    "        )\n",
    "        metric.add_batch(references=masks, predictions=pred_maps)\n",
    "\n",
    "# After compute the batches that were added are deleted\n",
    "mean_test_iou = metric.compute(\n",
    "    num_labels=NUM_CLASSES, ignore_index=0, reduce_labels=False\n",
    ")\n",
    "final_test_loss = test_running_loss / len(test_merged_loader.dataset)\n",
    "wandb.log({\n",
    "    \"Loss/test\": final_test_loss,\n",
    "    \"mIoU/test\": mean_test_iou\n",
    "})\n",
    "print(f\"Test Loss: {final_test_loss:.4f}, Test mIoU: {mean_test_iou}\")\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-09T14:34:44.285279Z",
     "iopub.status.busy": "2024-05-09T14:34:44.285141Z",
     "iopub.status.idle": "2024-05-09T14:34:48.431693Z",
     "shell.execute_reply": "2024-05-09T14:34:48.429839Z",
     "shell.execute_reply.started": "2024-05-09T14:34:44.285235Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.89021496, 0.63482789, 0.55386392, 0.55942563,\n",
       "       0.7503169 , 0.78523856, 0.73548494, 0.888148  , 0.93037863,\n",
       "       0.92560997])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_test_iou[\"per_category_iou\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
