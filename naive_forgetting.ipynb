{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a45b3d35-c225-4cc8-a513-7c2b3f62d810",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b55d5a14-5669-48a8-909b-9388c50b5240",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/notebooks/venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/notebooks/venv/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "from utils.common import (\n",
    "    m2f_dataset_collate,\n",
    "    m2f_extract_pred_maps_and_masks,\n",
    "    BG_VALUE,\n",
    "    set_seed,\n",
    "    pixel_mean_std,\n",
    "    CADIS_PIXEL_MEAN,\n",
    "    CADIS_PIXEL_STD,\n",
    "    CAT1K_PIXEL_MEAN,\n",
    "    CAT1K_PIXEL_STD,\n",
    ")\n",
    "from utils.dataset_utils import (\n",
    "    get_cadisv2_dataset,\n",
    "    get_cataract1k_dataset,\n",
    "    ZEISS_CATEGORIES,\n",
    ")\n",
    "from utils.medical_datasets import Mask2FormerDataset\n",
    "from transformers import (\n",
    "    Mask2FormerForUniversalSegmentation,\n",
    "    SwinModel,\n",
    "    SwinConfig,\n",
    "    Mask2FormerConfig,\n",
    "    AutoImageProcessor,\n",
    "    Mask2FormerImageProcessor\n",
    ")\n",
    "from torch.utils.data import DataLoader\n",
    "import evaluate\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import numpy as np\n",
    "from dotenv import load_dotenv\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18cdf6c1-f991-44d6-811c-5c8d98377076",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "set_seed(42) # seed everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "720a4418-3a26-4077-9338-5d820792afa1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d015d3b5-c9d5-4428-8714-0a0754165c18",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "NUM_CLASSES = len(ZEISS_CATEGORIES) - 3  # Remove class incremental\n",
    "model = Mask2FormerForUniversalSegmentation.from_pretrained(f\"outputs/models/m2f_swin_backbone_train_cadis/best_model/A\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b36595b1-0326-4a0b-97d5-5594a0f8aa16",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'A': {'train': <torch.utils.data.dataloader.DataLoader object at 0x7f1132ee4390>, 'val': <torch.utils.data.dataloader.DataLoader object at 0x7f125d34b110>, 'test': <torch.utils.data.dataloader.DataLoader object at 0x7f113c359b50>}, 'B': {'train': <torch.utils.data.dataloader.DataLoader object at 0x7f11313b0bd0>, 'val': <torch.utils.data.dataloader.DataLoader object at 0x7f11313b0d90>, 'test': <torch.utils.data.dataloader.DataLoader object at 0x7f11313b0ed0>}}\n"
     ]
    }
   ],
   "source": [
    "# Helper function to load datasets\n",
    "def load_dataset(dataset_getter, data_path, domain_incremental):\n",
    "    return dataset_getter(data_path, domain_incremental=domain_incremental)\n",
    "\n",
    "\n",
    "# Helper function to create dataloaders for a dataset\n",
    "def create_dataloaders(\n",
    "    dataset, batch_size, shuffle, num_workers, drop_last, pin_memory, collate_fn\n",
    "):\n",
    "    return {\n",
    "        \"train\": DataLoader(\n",
    "            dataset[\"train\"],\n",
    "            batch_size=batch_size,\n",
    "            shuffle=shuffle,\n",
    "            num_workers=num_workers,\n",
    "            drop_last=drop_last,\n",
    "            pin_memory=pin_memory,\n",
    "            collate_fn=collate_fn,\n",
    "        ),\n",
    "        \"val\": DataLoader(\n",
    "            dataset[\"val\"],\n",
    "            batch_size=batch_size,\n",
    "            shuffle=shuffle,\n",
    "            num_workers=num_workers,\n",
    "            drop_last=drop_last,\n",
    "            pin_memory=pin_memory,\n",
    "            collate_fn=collate_fn,\n",
    "        ),\n",
    "        \"test\": DataLoader(\n",
    "            dataset[\"test\"],\n",
    "            batch_size=batch_size,\n",
    "            shuffle=shuffle,\n",
    "            num_workers=num_workers,\n",
    "            drop_last=drop_last,\n",
    "            pin_memory=pin_memory,\n",
    "            collate_fn=collate_fn,\n",
    "        ),\n",
    "    }\n",
    "\n",
    "\n",
    "# Load datasets\n",
    "datasets = {\n",
    "    \"A\": load_dataset(get_cadisv2_dataset, \"../../storage/data/CaDISv2\", True),\n",
    "    \"B\": load_dataset(get_cataract1k_dataset, \"../../storage/data/cataract-1k\", True),\n",
    "}\n",
    "\n",
    "# pixel_mean_A,pixel_std_A=pixel_mean_std(datasets[\"A\"][0])\n",
    "pixel_mean_A = CADIS_PIXEL_MEAN\n",
    "pixel_std_A = CADIS_PIXEL_STD\n",
    "\n",
    "# pixel_mean_B,pixel_std_B=pixel_mean_std(datasets[\"B\"][0])\n",
    "pixel_mean_B = CAT1K_PIXEL_MEAN\n",
    "pixel_std_B = CAT1K_PIXEL_STD\n",
    "\n",
    "# Define preprocessor\n",
    "m2f_preprocessor_A = Mask2FormerImageProcessor(\n",
    "    reduce_labels=True,\n",
    "    ignore_index=255,\n",
    "    do_resize=False,\n",
    "    do_rescale=True,\n",
    "    do_normalize=True,\n",
    "    image_std=pixel_std_A,\n",
    "    image_mean=pixel_mean_A,\n",
    ")\n",
    "\n",
    "m2f_preprocessor_B = Mask2FormerImageProcessor(\n",
    "    reduce_labels=True,\n",
    "    ignore_index=255,\n",
    "    do_resize=False,\n",
    "    do_rescale=True,\n",
    "    do_normalize=True,\n",
    "    image_std=pixel_std_B,\n",
    "    image_mean=pixel_mean_B,\n",
    ")\n",
    "\n",
    "# Create Mask2Former Datasets\n",
    "m2f_datasets = {\n",
    "    \"A\": {\n",
    "        \"train\": Mask2FormerDataset(datasets[\"A\"][0], m2f_preprocessor_A),\n",
    "        \"val\": Mask2FormerDataset(datasets[\"A\"][1], m2f_preprocessor_A),\n",
    "        \"test\": Mask2FormerDataset(datasets[\"A\"][2], m2f_preprocessor_A),\n",
    "    },\n",
    "    \"B\": {\n",
    "        \"train\": Mask2FormerDataset(datasets[\"B\"][0], m2f_preprocessor_B),\n",
    "        \"val\": Mask2FormerDataset(datasets[\"B\"][1], m2f_preprocessor_B),\n",
    "        \"test\": Mask2FormerDataset(datasets[\"B\"][2], m2f_preprocessor_B),\n",
    "    },\n",
    "}\n",
    "\n",
    "# DataLoader parameters\n",
    "N_WORKERS = 4\n",
    "BATCH_SIZE = 16\n",
    "SHUFFLE = True\n",
    "DROP_LAST = True\n",
    "\n",
    "dataloader_params = {\n",
    "    \"batch_size\": BATCH_SIZE,\n",
    "    \"shuffle\": SHUFFLE,\n",
    "    \"num_workers\": N_WORKERS,\n",
    "    \"drop_last\": DROP_LAST,\n",
    "    \"pin_memory\": True,\n",
    "    \"collate_fn\": m2f_dataset_collate,\n",
    "}\n",
    "\n",
    "# Create DataLoaders\n",
    "dataloaders = {\n",
    "    key: create_dataloaders(m2f_datasets[key], **dataloader_params)\n",
    "    for key in m2f_datasets\n",
    "}\n",
    "\n",
    "print(dataloaders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fecd03a7-9482-4d19-a14c-869fd8c4de12",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-1c80317fa3b1799d\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-1c80317fa3b1799d\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Tensorboard setup\n",
    "out_dir=\"outputs/\"\n",
    "if not os.path.exists(out_dir):\n",
    "    os.makedirs(out_dir)\n",
    "if not os.path.exists(out_dir+\"runs\"):\n",
    "    os.makedirs(out_dir+\"runs\")\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir outputs/runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2541ebd0-d569-4fd4-95c8-69db59380633",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33manarlee\u001b[0m (\u001b[33mcontinual-learning-tum\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "67d5c7e1-62d8-41c9-b6e6-f857b8cd9318",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Tensorboard logging\n",
    "writer = SummaryWriter(log_dir=out_dir + \"runs\")\n",
    "\n",
    "# Model checkpointing\n",
    "base_model_name=\"naive_forgetting\"\n",
    "model_dir = out_dir + \"models/\"\n",
    "if not os.path.exists(model_dir):\n",
    "    print(\"Store weights in: \", model_dir)\n",
    "    os.makedirs(model_dir)\n",
    "\n",
    "best_model_dir = model_dir + f\"{base_model_name}/best_model/\"\n",
    "if not os.path.exists(best_model_dir):\n",
    "    print(\"Store best model weights in: \", best_model_dir)\n",
    "    os.makedirs(best_model_dir)\n",
    "final_model_dir = model_dir + f\"{base_model_name}/final_model/\"\n",
    "if not os.path.exists(final_model_dir):\n",
    "    print(\"Store final model weights in: \", final_model_dir)\n",
    "    os.makedirs(final_model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8eb1dd17-a403-4fbb-9ca1-59bda6de0c09",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['outputs/models/naive_forgetting/preprocessor_config.json']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m2f_preprocessor_A.save_pretrained(model_dir + base_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0d32d38c-a412-4f4a-b0d2-d0156afd4c2a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "metric = evaluate.load(\"mean_iou\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ad341f51-3a50-4992-b709-277ed50f6239",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test loop: 100%|██████████| 36/36 [00:33<00:00,  1.09it/s, loss=329.8553]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 15.0059, Test mIoU: 0.7352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.cache/huggingface/modules/evaluate_modules/metrics/evaluate-metric--mean_iou/9e450724f21f05592bfb0255fe2fa576df8171fa060d11121d8aecfff0db80d0/mean_iou.py:260: RuntimeWarning: invalid value encountered in divide\n",
      "  acc = total_area_intersect / total_area_label\n"
     ]
    }
   ],
   "source": [
    "CURR_TASK = \"A\"\n",
    "model.eval()\n",
    "test_running_loss = 0\n",
    "test_loader = tqdm(dataloaders[CURR_TASK][\"test\"], desc=\"Test loop\")\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        # Move everything to the device\n",
    "        batch[\"pixel_values\"] = batch[\"pixel_values\"].to(device)\n",
    "        batch[\"pixel_mask\"] = batch[\"pixel_mask\"].to(device)\n",
    "        batch[\"mask_labels\"] = [entry.to(device) for entry in batch[\"mask_labels\"]]\n",
    "        batch[\"class_labels\"] = [entry.to(device) for entry in batch[\"class_labels\"]]\n",
    "        # Compute output and loss\n",
    "        outputs = model(**batch)\n",
    "\n",
    "        loss = outputs.loss\n",
    "        # Record losses\n",
    "        current_loss = loss.item() * batch[\"pixel_values\"].size(0)\n",
    "        test_running_loss += current_loss\n",
    "        test_loader.set_postfix(loss=f\"{current_loss:.4f}\")\n",
    "\n",
    "        # Extract and compute metrics\n",
    "        pred_maps, masks = m2f_extract_pred_maps_and_masks(\n",
    "            batch, outputs, m2f_preprocessor_A\n",
    "        )\n",
    "        metric.add_batch(references=masks, predictions=pred_maps)\n",
    "        \n",
    "# After compute the batches that were added are deleted\n",
    "test_metrics_A = metric.compute(\n",
    "    num_labels=NUM_CLASSES, ignore_index=BG_VALUE, reduce_labels=False\n",
    ")\n",
    "mean_test_iou = test_metrics_A[\"mean_iou\"]\n",
    "final_test_loss = test_running_loss / len(dataloaders[CURR_TASK][\"test\"].dataset)\n",
    "# wandb.log({\n",
    "#     f\"Loss/test_{CURR_TASK}\": final_test_loss,\n",
    "#     f\"mIoU/test_{CURR_TASK}\": mean_test_iou\n",
    "# })\n",
    "print(f\"Test Loss: {final_test_loss:.4f}, Test mIoU: {mean_test_iou:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4701281f-40fb-43cb-b060-9440c2f14063",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Training\n",
    "NUM_EPOCHS = 200\n",
    "LEARNING_RATE = 1e-4\n",
    "LR_MULTIPLIER = 0.1\n",
    "BACKBONE_LR = LEARNING_RATE * LR_MULTIPLIER\n",
    "WEIGHT_DECAY = 0.05\n",
    "encoder_params = [\n",
    "    param\n",
    "    for name, param in model.named_parameters()\n",
    "    if name.startswith(\"model.pixel_level_module.encoder\")\n",
    "]\n",
    "decoder_params = [\n",
    "    param\n",
    "    for name, param in model.named_parameters()\n",
    "    if name.startswith(\"model.pixel_level_module.decoder\")\n",
    "]\n",
    "transformer_params = [\n",
    "    param\n",
    "    for name, param in model.named_parameters()\n",
    "    if name.startswith(\"model.transformer_module\")\n",
    "]\n",
    "optimizer = optim.AdamW(\n",
    "    [\n",
    "        {\"params\": encoder_params, \"lr\": BACKBONE_LR},\n",
    "        {\"params\": decoder_params},\n",
    "        {\"params\": transformer_params},\n",
    "    ],\n",
    "    lr=LEARNING_RATE,\n",
    "    weight_decay=WEIGHT_DECAY,\n",
    ")\n",
    "\n",
    "scheduler = optim.lr_scheduler.PolynomialLR(\n",
    "    optimizer, total_iters=NUM_EPOCHS, power=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "96b64eda-c8cc-4d4b-8bfe-8bd9b1f6dcc7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/notebooks/continual-learning/wandb/run-20240516_001126-tr1kxq1j</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/continual-learning-tum/M2F_original/runs/tr1kxq1j' target=\"_blank\">M2F-Swin-Tiny-Naive-Forgetting-200</a></strong> to <a href='https://wandb.ai/continual-learning-tum/M2F_original' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/continual-learning-tum/M2F_original' target=\"_blank\">https://wandb.ai/continual-learning-tum/M2F_original</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/continual-learning-tum/M2F_original/runs/tr1kxq1j' target=\"_blank\">https://wandb.ai/continual-learning-tum/M2F_original/runs/tr1kxq1j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.init(\n",
    "    project=\"M2F_original\",\n",
    "    config={\n",
    "        \"learning_rate\": LEARNING_RATE,\n",
    "        \"learning_rate_multiplier\": LR_MULTIPLIER,\n",
    "        \"backbone_learning_rate\": BACKBONE_LR,\n",
    "        \"learning_rate_scheduler\": scheduler.__class__.__name__,\n",
    "        \"optimizer\": optimizer.__class__.__name__,\n",
    "        \"backbone\": \"m2f_swin_backbone_train_cadis\",\n",
    "        \"m2f_preprocessor\": m2f_preprocessor_B.__dict__,\n",
    "        \"m2f_model_config\": model.config\n",
    "    },\n",
    "    name=\"M2F-Swin-Tiny-Naive-Forgetting-200\",\n",
    "    notes=\"M2F with tiny Swin backbone pretrained on ImageNet-1K. \\\n",
    "        Scenario: Pretrained on A, Train on B, Test forgetting on A\"\n",
    ")\n",
    "# Tensorboard logging\n",
    "writer = SummaryWriter(log_dir=out_dir + \"runs\")\n",
    "# Model checkpointing\n",
    "model_name = \"m2f_swin_backbone_naive_forgetting-b\"\n",
    "model_dir = out_dir + \"models/\"\n",
    "if not os.path.exists(model_dir):\n",
    "    print(\"Store weights in: \", model_dir)\n",
    "    os.makedirs(model_dir)\n",
    "\n",
    "best_model_dir = model_dir + f\"{model_name}/best_model/\"\n",
    "if not os.path.exists(best_model_dir):\n",
    "    print(\"Store best model weights in: \", best_model_dir)\n",
    "    os.makedirs(best_model_dir)\n",
    "final_model_dir = model_dir + f\"{model_name}/final_model/\"\n",
    "if not os.path.exists(final_model_dir):\n",
    "    print(\"Store final model weights in: \", final_model_dir)\n",
    "    os.makedirs(final_model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2a214bd6-aab2-4021-bbca-5185b01f8ef0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['outputs/models/m2f_swin_backbone_naive_forgetting-b/preprocessor_config.json']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m2f_preprocessor_B.save_pretrained(model_dir + model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bf6d22c9-2802-40d6-b1fc-52fc75a1d07e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/200 Training: 100%|██████████| 112/112 [01:57<00:00,  1.05s/it, loss=275.9501]\n",
      "/root/.cache/huggingface/modules/evaluate_modules/metrics/evaluate-metric--mean_iou/9e450724f21f05592bfb0255fe2fa576df8171fa060d11121d8aecfff0db80d0/mean_iou.py:260: RuntimeWarning: invalid value encountered in divide\n",
      "  acc = total_area_intersect / total_area_label\n",
      "Epoch 1/200 Validation: 100%|██████████| 14/14 [00:09<00:00,  1.46it/s, loss=253.6964]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200, Train Loss: 22.9025, Train mIoU: 0.4203, Validation Loss: 16.6096, Validation mIoU: 0.5314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/200 Training: 100%|██████████| 112/112 [02:01<00:00,  1.08s/it, loss=240.8674]\n",
      "Epoch 2/200 Validation: 100%|██████████| 14/14 [00:14<00:00,  1.01s/it, loss=190.2122]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/200, Train Loss: 15.5788, Train mIoU: 0.5907, Validation Loss: 11.7769, Validation mIoU: 0.7086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/200 Training: 100%|██████████| 112/112 [02:00<00:00,  1.08s/it, loss=127.9669]\n",
      "Epoch 3/200 Validation: 100%|██████████| 14/14 [00:09<00:00,  1.48it/s, loss=147.2661]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/200, Train Loss: 11.8668, Train mIoU: 0.7144, Validation Loss: 10.3128, Validation mIoU: 0.7349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/200 Training: 100%|██████████| 112/112 [02:03<00:00,  1.11s/it, loss=137.3650]\n",
      "Epoch 4/200 Validation: 100%|██████████| 14/14 [00:10<00:00,  1.36it/s, loss=181.9393]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/200, Train Loss: 10.0055, Train mIoU: 0.7534, Validation Loss: 9.3656, Validation mIoU: 0.7713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/200 Training: 100%|██████████| 112/112 [01:57<00:00,  1.05s/it, loss=141.9254]\n",
      "Epoch 5/200 Validation: 100%|██████████| 14/14 [00:08<00:00,  1.58it/s, loss=162.7552]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/200, Train Loss: 8.9175, Train mIoU: 0.7676, Validation Loss: 9.6687, Validation mIoU: 0.7280\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/200 Training: 100%|██████████| 112/112 [02:06<00:00,  1.13s/it, loss=137.1364]\n",
      "Epoch 6/200 Validation: 100%|██████████| 14/14 [00:12<00:00,  1.12it/s, loss=153.3968]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/200, Train Loss: 8.4230, Train mIoU: 0.7877, Validation Loss: 8.8760, Validation mIoU: 0.7461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/200 Training: 100%|██████████| 112/112 [02:01<00:00,  1.08s/it, loss=119.9177]\n",
      "Epoch 7/200 Validation: 100%|██████████| 14/14 [00:10<00:00,  1.29it/s, loss=141.6956]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/200, Train Loss: 7.8464, Train mIoU: 0.8103, Validation Loss: 8.6316, Validation mIoU: 0.7664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/200 Training: 100%|██████████| 112/112 [02:05<00:00,  1.12s/it, loss=149.1364]\n",
      "Epoch 8/200 Validation: 100%|██████████| 14/14 [00:11<00:00,  1.21it/s, loss=115.0689]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/200, Train Loss: 7.5442, Train mIoU: 0.8184, Validation Loss: 8.0913, Validation mIoU: 0.7644\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/200 Training: 100%|██████████| 112/112 [02:05<00:00,  1.12s/it, loss=115.7365]\n",
      "Epoch 9/200 Validation: 100%|██████████| 14/14 [00:09<00:00,  1.40it/s, loss=111.9807]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/200, Train Loss: 7.1263, Train mIoU: 0.8359, Validation Loss: 8.3469, Validation mIoU: 0.7508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/200 Training: 100%|██████████| 112/112 [02:03<00:00,  1.11s/it, loss=149.6504]\n",
      "Epoch 10/200 Validation: 100%|██████████| 14/14 [00:09<00:00,  1.45it/s, loss=167.7110]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/200, Train Loss: 7.6502, Train mIoU: 0.8257, Validation Loss: 11.6121, Validation mIoU: 0.6923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/200 Training: 100%|██████████| 112/112 [02:01<00:00,  1.08s/it, loss=114.1203]\n",
      "Epoch 11/200 Validation: 100%|██████████| 14/14 [00:09<00:00,  1.51it/s, loss=105.6527]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/200, Train Loss: 7.0374, Train mIoU: 0.8246, Validation Loss: 8.1429, Validation mIoU: 0.7429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/200 Training: 100%|██████████| 112/112 [02:01<00:00,  1.08s/it, loss=107.9282]\n",
      "Epoch 12/200 Validation: 100%|██████████| 14/14 [00:09<00:00,  1.52it/s, loss=128.7861]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/200, Train Loss: 6.5493, Train mIoU: 0.8526, Validation Loss: 8.1093, Validation mIoU: 0.7662\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/200 Training: 100%|██████████| 112/112 [02:05<00:00,  1.12s/it, loss=140.8829]\n",
      "Epoch 13/200 Validation: 100%|██████████| 14/14 [00:09<00:00,  1.47it/s, loss=103.5610]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/200, Train Loss: 6.6065, Train mIoU: 0.8491, Validation Loss: 8.6595, Validation mIoU: 0.7736\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/200 Training: 100%|██████████| 112/112 [02:05<00:00,  1.12s/it, loss=103.5890]\n",
      "Epoch 14/200 Validation: 100%|██████████| 14/14 [00:10<00:00,  1.38it/s, loss=132.5417]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/200, Train Loss: 6.2999, Train mIoU: 0.8419, Validation Loss: 8.1991, Validation mIoU: 0.7450\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/200 Training: 100%|██████████| 112/112 [02:00<00:00,  1.08s/it, loss=100.5470]\n",
      "Epoch 15/200 Validation: 100%|██████████| 14/14 [00:09<00:00,  1.45it/s, loss=134.3832]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/200, Train Loss: 6.3554, Train mIoU: 0.8532, Validation Loss: 7.7134, Validation mIoU: 0.7579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/200 Training: 100%|██████████| 112/112 [01:59<00:00,  1.07s/it, loss=91.1026]\n",
      "Epoch 16/200 Validation: 100%|██████████| 14/14 [00:13<00:00,  1.04it/s, loss=112.0637]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/200, Train Loss: 5.8959, Train mIoU: 0.8605, Validation Loss: 7.7093, Validation mIoU: 0.7703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/200 Training: 100%|██████████| 112/112 [01:59<00:00,  1.07s/it, loss=95.7740] \n",
      "Epoch 17/200 Validation: 100%|██████████| 14/14 [00:09<00:00,  1.47it/s, loss=120.1680]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/200, Train Loss: 5.8645, Train mIoU: 0.8636, Validation Loss: 8.0901, Validation mIoU: 0.7598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/200 Training: 100%|██████████| 112/112 [01:59<00:00,  1.07s/it, loss=102.4421]\n",
      "Epoch 18/200 Validation: 100%|██████████| 14/14 [00:12<00:00,  1.11it/s, loss=130.3600]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/200, Train Loss: 5.6744, Train mIoU: 0.8674, Validation Loss: 7.6826, Validation mIoU: 0.7549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/200 Training: 100%|██████████| 112/112 [02:02<00:00,  1.09s/it, loss=79.3289] \n",
      "Epoch 19/200 Validation: 100%|██████████| 14/14 [00:10<00:00,  1.33it/s, loss=105.0657]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/200, Train Loss: 5.6974, Train mIoU: 0.8616, Validation Loss: 8.4423, Validation mIoU: 0.7469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/200 Training: 100%|██████████| 112/112 [02:07<00:00,  1.14s/it, loss=84.5511] \n",
      "Epoch 20/200 Validation: 100%|██████████| 14/14 [00:12<00:00,  1.13it/s, loss=118.5611]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/200, Train Loss: 5.4746, Train mIoU: 0.8757, Validation Loss: 7.8613, Validation mIoU: 0.7554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/200 Training: 100%|██████████| 112/112 [02:02<00:00,  1.10s/it, loss=85.7838] \n",
      "Epoch 21/200 Validation: 100%|██████████| 14/14 [00:11<00:00,  1.17it/s, loss=165.8735]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/200, Train Loss: 5.4987, Train mIoU: 0.8660, Validation Loss: 7.8093, Validation mIoU: 0.7435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22/200 Training: 100%|██████████| 112/112 [02:00<00:00,  1.08s/it, loss=97.2870] \n",
      "Epoch 22/200 Validation: 100%|██████████| 14/14 [00:09<00:00,  1.46it/s, loss=127.4018]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/200, Train Loss: 5.4203, Train mIoU: 0.8763, Validation Loss: 8.2343, Validation mIoU: 0.6659\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23/200 Training: 100%|██████████| 112/112 [02:04<00:00,  1.11s/it, loss=106.7787]\n",
      "Epoch 23/200 Validation: 100%|██████████| 14/14 [00:09<00:00,  1.47it/s, loss=126.8006]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/200, Train Loss: 5.4855, Train mIoU: 0.8719, Validation Loss: 7.9564, Validation mIoU: 0.7717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24/200 Training: 100%|██████████| 112/112 [01:58<00:00,  1.06s/it, loss=95.3583] \n",
      "Epoch 24/200 Validation: 100%|██████████| 14/14 [00:09<00:00,  1.43it/s, loss=139.3829]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/200, Train Loss: 5.6196, Train mIoU: 0.8440, Validation Loss: 7.9240, Validation mIoU: 0.7825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25/200 Training: 100%|██████████| 112/112 [01:59<00:00,  1.07s/it, loss=78.6507]\n",
      "Epoch 25/200 Validation: 100%|██████████| 14/14 [00:09<00:00,  1.48it/s, loss=123.3385]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/200, Train Loss: 5.1429, Train mIoU: 0.8688, Validation Loss: 7.5422, Validation mIoU: 0.7627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26/200 Training: 100%|██████████| 112/112 [01:58<00:00,  1.06s/it, loss=77.3643]\n",
      "Epoch 26/200 Validation: 100%|██████████| 14/14 [00:14<00:00,  1.01s/it, loss=91.9193] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/200, Train Loss: 4.8606, Train mIoU: 0.8824, Validation Loss: 7.5539, Validation mIoU: 0.7718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27/200 Training: 100%|██████████| 112/112 [02:05<00:00,  1.12s/it, loss=69.6758]\n",
      "Epoch 27/200 Validation: 100%|██████████| 14/14 [00:10<00:00,  1.29it/s, loss=110.6696]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/200, Train Loss: 4.8508, Train mIoU: 0.8692, Validation Loss: 7.5291, Validation mIoU: 0.7429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28/200 Training: 100%|██████████| 112/112 [01:59<00:00,  1.06s/it, loss=69.4213]\n",
      "Epoch 28/200 Validation: 100%|██████████| 14/14 [00:11<00:00,  1.27it/s, loss=94.3941] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/200, Train Loss: 4.8242, Train mIoU: 0.8767, Validation Loss: 7.6581, Validation mIoU: 0.7725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29/200 Training: 100%|██████████| 112/112 [02:10<00:00,  1.17s/it, loss=69.8156]\n",
      "Epoch 29/200 Validation: 100%|██████████| 14/14 [00:09<00:00,  1.48it/s, loss=150.8713]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/200, Train Loss: 4.7298, Train mIoU: 0.8809, Validation Loss: 7.7486, Validation mIoU: 0.7211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30/200 Training: 100%|██████████| 112/112 [02:00<00:00,  1.08s/it, loss=70.1466]\n",
      "Epoch 30/200 Validation: 100%|██████████| 14/14 [00:12<00:00,  1.13it/s, loss=105.8971]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/200, Train Loss: 4.7730, Train mIoU: 0.8734, Validation Loss: 8.1137, Validation mIoU: 0.7762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31/200 Training: 100%|██████████| 112/112 [02:04<00:00,  1.11s/it, loss=64.4183]\n",
      "Epoch 31/200 Validation: 100%|██████████| 14/14 [00:12<00:00,  1.09it/s, loss=116.5353]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/200, Train Loss: 4.7995, Train mIoU: 0.8809, Validation Loss: 7.5503, Validation mIoU: 0.7862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33/200 Training: 100%|██████████| 112/112 [02:05<00:00,  1.12s/it, loss=69.5825]\n",
      "Epoch 33/200 Validation: 100%|██████████| 14/14 [00:13<00:00,  1.04it/s, loss=107.2553]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/200, Train Loss: 4.5929, Train mIoU: 0.8785, Validation Loss: 7.6055, Validation mIoU: 0.7619\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34/200 Training: 100%|██████████| 112/112 [02:01<00:00,  1.09s/it, loss=74.7053]\n",
      "Epoch 34/200 Validation: 100%|██████████| 14/14 [00:11<00:00,  1.23it/s, loss=149.1676]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/200, Train Loss: 4.5238, Train mIoU: 0.8840, Validation Loss: 7.4858, Validation mIoU: 0.7518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35/200 Training: 100%|██████████| 112/112 [02:07<00:00,  1.14s/it, loss=89.8614]\n",
      "Epoch 35/200 Validation: 100%|██████████| 14/14 [00:09<00:00,  1.40it/s, loss=105.7646]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/200, Train Loss: 4.7800, Train mIoU: 0.8839, Validation Loss: 8.4405, Validation mIoU: 0.7332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36/200 Training: 100%|██████████| 112/112 [01:58<00:00,  1.06s/it, loss=74.8241]\n",
      "Epoch 36/200 Validation: 100%|██████████| 14/14 [00:10<00:00,  1.34it/s, loss=129.0229]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/200, Train Loss: 5.1755, Train mIoU: 0.8692, Validation Loss: 7.8997, Validation mIoU: 0.6674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37/200 Training: 100%|██████████| 112/112 [02:07<00:00,  1.14s/it, loss=66.2714]\n",
      "Epoch 37/200 Validation: 100%|██████████| 14/14 [00:10<00:00,  1.35it/s, loss=131.9821]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/200, Train Loss: 4.9682, Train mIoU: 0.8507, Validation Loss: 7.5454, Validation mIoU: 0.7733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38/200 Training: 100%|██████████| 112/112 [02:01<00:00,  1.09s/it, loss=80.8728]\n",
      "Epoch 38/200 Validation: 100%|██████████| 14/14 [00:09<00:00,  1.51it/s, loss=134.4797]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/200, Train Loss: 4.7400, Train mIoU: 0.8682, Validation Loss: 7.5057, Validation mIoU: 0.7645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39/200 Training: 100%|██████████| 112/112 [02:09<00:00,  1.15s/it, loss=71.0283]\n",
      "Epoch 39/200 Validation: 100%|██████████| 14/14 [00:10<00:00,  1.29it/s, loss=107.7461]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/200, Train Loss: 4.2832, Train mIoU: 0.8865, Validation Loss: 7.5352, Validation mIoU: 0.7557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40/200 Training: 100%|██████████| 112/112 [02:08<00:00,  1.15s/it, loss=71.0680]\n",
      "Epoch 40/200 Validation: 100%|██████████| 14/14 [00:10<00:00,  1.30it/s, loss=134.2769]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/200, Train Loss: 4.2970, Train mIoU: 0.8853, Validation Loss: 7.6954, Validation mIoU: 0.8001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41/200 Training: 100%|██████████| 112/112 [02:04<00:00,  1.11s/it, loss=69.4115]\n",
      "Epoch 41/200 Validation: 100%|██████████| 14/14 [00:11<00:00,  1.27it/s, loss=96.4566] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/200, Train Loss: 4.2057, Train mIoU: 0.8809, Validation Loss: 7.5585, Validation mIoU: 0.7909\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 42/200 Training: 100%|██████████| 112/112 [01:57<00:00,  1.05s/it, loss=65.4313]\n",
      "Epoch 42/200 Validation: 100%|██████████| 14/14 [00:09<00:00,  1.40it/s, loss=127.2476]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/200, Train Loss: 4.0823, Train mIoU: 0.8818, Validation Loss: 7.4293, Validation mIoU: 0.7745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 43/200 Training: 100%|██████████| 112/112 [01:57<00:00,  1.05s/it, loss=67.3288]\n",
      "Epoch 43/200 Validation: 100%|██████████| 14/14 [00:10<00:00,  1.34it/s, loss=99.6713] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/200, Train Loss: 4.0455, Train mIoU: 0.8891, Validation Loss: 7.5998, Validation mIoU: 0.7858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 44/200 Training: 100%|██████████| 112/112 [02:05<00:00,  1.12s/it, loss=75.1746]\n",
      "Epoch 44/200 Validation: 100%|██████████| 14/14 [00:14<00:00,  1.05s/it, loss=121.9317]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/200, Train Loss: 4.0979, Train mIoU: 0.8800, Validation Loss: 7.7144, Validation mIoU: 0.8081\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 45/200 Training: 100%|██████████| 112/112 [02:00<00:00,  1.08s/it, loss=73.5646] \n",
      "Epoch 45/200 Validation: 100%|██████████| 14/14 [00:10<00:00,  1.38it/s, loss=183.4653]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/200, Train Loss: 4.1068, Train mIoU: 0.8818, Validation Loss: 7.8322, Validation mIoU: 0.7753\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 46/200 Training: 100%|██████████| 112/112 [02:03<00:00,  1.10s/it, loss=63.7483]\n",
      "Epoch 46/200 Validation: 100%|██████████| 14/14 [00:10<00:00,  1.33it/s, loss=99.4504] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/200, Train Loss: 4.2388, Train mIoU: 0.8816, Validation Loss: 7.7437, Validation mIoU: 0.7808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 47/200 Training: 100%|██████████| 112/112 [02:00<00:00,  1.08s/it, loss=67.5670] \n",
      "Epoch 47/200 Validation: 100%|██████████| 14/14 [00:10<00:00,  1.32it/s, loss=154.7922]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/200, Train Loss: 4.7092, Train mIoU: 0.8360, Validation Loss: 7.8529, Validation mIoU: 0.6435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 48/200 Training: 100%|██████████| 112/112 [02:03<00:00,  1.10s/it, loss=67.8108]\n",
      "Epoch 48/200 Validation: 100%|██████████| 14/14 [00:13<00:00,  1.05it/s, loss=184.1185]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/200, Train Loss: 4.1567, Train mIoU: 0.8536, Validation Loss: 7.6363, Validation mIoU: 0.7509\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 49/200 Training: 100%|██████████| 112/112 [02:07<00:00,  1.14s/it, loss=68.5038]\n",
      "Epoch 49/200 Validation: 100%|██████████| 14/14 [00:10<00:00,  1.36it/s, loss=144.8727]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/200, Train Loss: 3.9774, Train mIoU: 0.8854, Validation Loss: 7.3830, Validation mIoU: 0.7947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 50/200 Training: 100%|██████████| 112/112 [02:02<00:00,  1.09s/it, loss=80.0469]\n",
      "Epoch 50/200 Validation: 100%|██████████| 14/14 [00:13<00:00,  1.04it/s, loss=93.6114] \n",
      "/root/.cache/huggingface/modules/evaluate_modules/metrics/evaluate-metric--mean_iou/9e450724f21f05592bfb0255fe2fa576df8171fa060d11121d8aecfff0db80d0/mean_iou.py:259: RuntimeWarning: invalid value encountered in divide\n",
      "  iou = total_area_intersect / total_area_union\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/200, Train Loss: 3.9850, Train mIoU: 0.8873, Validation Loss: 8.0967, Validation mIoU: 0.8273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 51/200 Training: 100%|██████████| 112/112 [02:00<00:00,  1.08s/it, loss=62.3284]\n",
      "Epoch 51/200 Validation: 100%|██████████| 14/14 [00:09<00:00,  1.40it/s, loss=139.4620]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51/200, Train Loss: 4.1917, Train mIoU: 0.8847, Validation Loss: 7.5094, Validation mIoU: 0.7720\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 52/200 Training: 100%|██████████| 112/112 [02:05<00:00,  1.12s/it, loss=62.2683]\n",
      "Epoch 52/200 Validation: 100%|██████████| 14/14 [00:13<00:00,  1.03it/s, loss=110.8706]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52/200, Train Loss: 3.9174, Train mIoU: 0.8818, Validation Loss: 7.5836, Validation mIoU: 0.7583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 53/200 Training: 100%|██████████| 112/112 [01:57<00:00,  1.05s/it, loss=62.0481]\n",
      "Epoch 53/200 Validation: 100%|██████████| 14/14 [00:09<00:00,  1.47it/s, loss=108.3047]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/200, Train Loss: 3.8526, Train mIoU: 0.8901, Validation Loss: 7.4731, Validation mIoU: 0.7648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 54/200 Training: 100%|██████████| 112/112 [02:05<00:00,  1.12s/it, loss=61.7987]\n",
      "Epoch 54/200 Validation: 100%|██████████| 14/14 [00:09<00:00,  1.44it/s, loss=103.0588]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54/200, Train Loss: 3.8799, Train mIoU: 0.8894, Validation Loss: 7.6549, Validation mIoU: 0.7419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 55/200 Training: 100%|██████████| 112/112 [02:05<00:00,  1.12s/it, loss=58.2066]\n",
      "Epoch 55/200 Validation: 100%|██████████| 14/14 [00:09<00:00,  1.41it/s, loss=110.3214]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/200, Train Loss: 3.8539, Train mIoU: 0.8894, Validation Loss: 7.5258, Validation mIoU: 0.7717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 56/200 Training: 100%|██████████| 112/112 [02:03<00:00,  1.11s/it, loss=69.9409]\n",
      "Epoch 56/200 Validation: 100%|██████████| 14/14 [00:09<00:00,  1.41it/s, loss=103.1507]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/200, Train Loss: 3.7151, Train mIoU: 0.8910, Validation Loss: 7.1401, Validation mIoU: 0.7982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 57/200 Training: 100%|██████████| 112/112 [01:59<00:00,  1.07s/it, loss=47.3391]\n",
      "Epoch 57/200 Validation: 100%|██████████| 14/14 [00:11<00:00,  1.25it/s, loss=94.8212] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/200, Train Loss: 3.6864, Train mIoU: 0.8870, Validation Loss: 7.6190, Validation mIoU: 0.7796\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 58/200 Training: 100%|██████████| 112/112 [01:59<00:00,  1.07s/it, loss=65.5836]\n",
      "Epoch 58/200 Validation: 100%|██████████| 14/14 [00:14<00:00,  1.05s/it, loss=88.5024] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/200, Train Loss: 3.6370, Train mIoU: 0.8886, Validation Loss: 7.6808, Validation mIoU: 0.7551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 59/200 Training: 100%|██████████| 112/112 [02:01<00:00,  1.08s/it, loss=67.7087]\n",
      "Epoch 59/200 Validation: 100%|██████████| 14/14 [00:13<00:00,  1.05it/s, loss=107.8220]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/200, Train Loss: 3.6872, Train mIoU: 0.8887, Validation Loss: 7.8004, Validation mIoU: 0.7720\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 60/200 Training: 100%|██████████| 112/112 [01:58<00:00,  1.05s/it, loss=66.8611]\n"
     ]
    },
    {
     "ename": "UnidentifiedImageError",
     "evalue": "cannot identify image file <_io.BytesIO object at 0x7f117ee3f3d0>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnidentifiedImageError\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 49\u001b[0m\n\u001b[1;32m     46\u001b[0m     metric\u001b[38;5;241m.\u001b[39madd_batch(references\u001b[38;5;241m=\u001b[39mmasks, predictions\u001b[38;5;241m=\u001b[39mpred_maps)\n\u001b[1;32m     48\u001b[0m \u001b[38;5;66;03m# After compute the batches that were added are deleted\u001b[39;00m\n\u001b[0;32m---> 49\u001b[0m mean_train_iou \u001b[38;5;241m=\u001b[39m \u001b[43mmetric\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_labels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mNUM_CLASSES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mBG_VALUE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduce_labels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[1;32m     51\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean_iou\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     53\u001b[0m \u001b[38;5;66;03m# Validation phase\u001b[39;00m\n\u001b[1;32m     54\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n",
      "File \u001b[0;32m/notebooks/venv/lib/python3.11/site-packages/evaluate/module.py:465\u001b[0m, in \u001b[0;36mEvaluationModule.compute\u001b[0;34m(self, predictions, references, **kwargs)\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess_id \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    463\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mset_format(\u001b[38;5;28mtype\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfo\u001b[38;5;241m.\u001b[39mformat)\n\u001b[0;32m--> 465\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m \u001b[43m{\u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_feature_names\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m\n\u001b[1;32m    466\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m temp_seed(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseed):\n\u001b[1;32m    467\u001b[0m         output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compute(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcompute_kwargs)\n",
      "File \u001b[0;32m/notebooks/venv/lib/python3.11/site-packages/evaluate/module.py:465\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess_id \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    463\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mset_format(\u001b[38;5;28mtype\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfo\u001b[38;5;241m.\u001b[39mformat)\n\u001b[0;32m--> 465\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m {input_name: \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m input_name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_feature_names()}\n\u001b[1;32m    466\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m temp_seed(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseed):\n\u001b[1;32m    467\u001b[0m         output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compute(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcompute_kwargs)\n",
      "File \u001b[0;32m/notebooks/venv/lib/python3.11/site-packages/datasets/arrow_dataset.py:2861\u001b[0m, in \u001b[0;36mDataset.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2859\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):  \u001b[38;5;66;03m# noqa: F811\u001b[39;00m\n\u001b[1;32m   2860\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Can be used to index columns (by string names) or rows (by integer index or iterable of indices or bools).\"\"\"\u001b[39;00m\n\u001b[0;32m-> 2861\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/notebooks/venv/lib/python3.11/site-packages/datasets/arrow_dataset.py:2846\u001b[0m, in \u001b[0;36mDataset._getitem\u001b[0;34m(self, key, **kwargs)\u001b[0m\n\u001b[1;32m   2844\u001b[0m formatter \u001b[38;5;241m=\u001b[39m get_formatter(format_type, features\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info\u001b[38;5;241m.\u001b[39mfeatures, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mformat_kwargs)\n\u001b[1;32m   2845\u001b[0m pa_subtable \u001b[38;5;241m=\u001b[39m query_table(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data, key, indices\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_indices)\n\u001b[0;32m-> 2846\u001b[0m formatted_output \u001b[38;5;241m=\u001b[39m \u001b[43mformat_table\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2847\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpa_subtable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mformatter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mformatter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mformat_columns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mformat_columns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_all_columns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_all_columns\u001b[49m\n\u001b[1;32m   2848\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2849\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m formatted_output\n",
      "File \u001b[0;32m/notebooks/venv/lib/python3.11/site-packages/datasets/formatting/formatting.py:633\u001b[0m, in \u001b[0;36mformat_table\u001b[0;34m(table, key, formatter, format_columns, output_all_columns)\u001b[0m\n\u001b[1;32m    631\u001b[0m python_formatter \u001b[38;5;241m=\u001b[39m PythonFormatter(features\u001b[38;5;241m=\u001b[39mformatter\u001b[38;5;241m.\u001b[39mfeatures)\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m format_columns \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 633\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mformatter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpa_table\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery_type\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    634\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m query_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumn\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    635\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m format_columns:\n",
      "File \u001b[0;32m/notebooks/venv/lib/python3.11/site-packages/datasets/formatting/formatting.py:399\u001b[0m, in \u001b[0;36mFormatter.__call__\u001b[0;34m(self, pa_table, query_type)\u001b[0m\n\u001b[1;32m    397\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mformat_row(pa_table)\n\u001b[1;32m    398\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m query_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumn\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 399\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat_column\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpa_table\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    400\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m query_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    401\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mformat_batch(pa_table)\n",
      "File \u001b[0;32m/notebooks/venv/lib/python3.11/site-packages/datasets/formatting/formatting.py:443\u001b[0m, in \u001b[0;36mPythonFormatter.format_column\u001b[0;34m(self, pa_table)\u001b[0m\n\u001b[1;32m    441\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mformat_column\u001b[39m(\u001b[38;5;28mself\u001b[39m, pa_table: pa\u001b[38;5;241m.\u001b[39mTable) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m:\n\u001b[1;32m    442\u001b[0m     column \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpython_arrow_extractor()\u001b[38;5;241m.\u001b[39mextract_column(pa_table)\n\u001b[0;32m--> 443\u001b[0m     column \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpython_features_decoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode_column\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolumn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpa_table\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumn_names\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    444\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m column\n",
      "File \u001b[0;32m/notebooks/venv/lib/python3.11/site-packages/datasets/formatting/formatting.py:219\u001b[0m, in \u001b[0;36mPythonFeaturesDecoder.decode_column\u001b[0;34m(self, column, column_name)\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode_column\u001b[39m(\u001b[38;5;28mself\u001b[39m, column: \u001b[38;5;28mlist\u001b[39m, column_name: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m:\n\u001b[0;32m--> 219\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeatures\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode_column\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolumn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumn_name\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeatures \u001b[38;5;28;01melse\u001b[39;00m column\n",
      "File \u001b[0;32m/notebooks/venv/lib/python3.11/site-packages/datasets/features/features.py:1997\u001b[0m, in \u001b[0;36mFeatures.decode_column\u001b[0;34m(self, column, column_name)\u001b[0m\n\u001b[1;32m   1984\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode_column\u001b[39m(\u001b[38;5;28mself\u001b[39m, column: \u001b[38;5;28mlist\u001b[39m, column_name: \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m   1985\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Decode column with custom feature decoding.\u001b[39;00m\n\u001b[1;32m   1986\u001b[0m \n\u001b[1;32m   1987\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1994\u001b[0m \u001b[38;5;124;03m        `list[Any]`\u001b[39;00m\n\u001b[1;32m   1995\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   1996\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m-> 1997\u001b[0m         \u001b[43m[\u001b[49m\u001b[43mdecode_nested_example\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mcolumn_name\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcolumn\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m   1998\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_column_requires_decoding[column_name]\n\u001b[1;32m   1999\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m column\n\u001b[1;32m   2000\u001b[0m     )\n",
      "File \u001b[0;32m/notebooks/venv/lib/python3.11/site-packages/datasets/features/features.py:1997\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1984\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode_column\u001b[39m(\u001b[38;5;28mself\u001b[39m, column: \u001b[38;5;28mlist\u001b[39m, column_name: \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m   1985\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Decode column with custom feature decoding.\u001b[39;00m\n\u001b[1;32m   1986\u001b[0m \n\u001b[1;32m   1987\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1994\u001b[0m \u001b[38;5;124;03m        `list[Any]`\u001b[39;00m\n\u001b[1;32m   1995\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   1996\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m-> 1997\u001b[0m         [\u001b[43mdecode_nested_example\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mcolumn_name\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m value \u001b[38;5;129;01min\u001b[39;00m column]\n\u001b[1;32m   1998\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_column_requires_decoding[column_name]\n\u001b[1;32m   1999\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m column\n\u001b[1;32m   2000\u001b[0m     )\n",
      "File \u001b[0;32m/notebooks/venv/lib/python3.11/site-packages/datasets/features/features.py:1341\u001b[0m, in \u001b[0;36mdecode_nested_example\u001b[0;34m(schema, obj, token_per_repo_id)\u001b[0m\n\u001b[1;32m   1338\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(schema, (Audio, Image)):\n\u001b[1;32m   1339\u001b[0m     \u001b[38;5;66;03m# we pass the token to read and decode files from private repositories in streaming mode\u001b[39;00m\n\u001b[1;32m   1340\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m schema\u001b[38;5;241m.\u001b[39mdecode:\n\u001b[0;32m-> 1341\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mschema\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode_example\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken_per_repo_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_per_repo_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1342\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj\n",
      "File \u001b[0;32m/notebooks/venv/lib/python3.11/site-packages/datasets/features/image.py:187\u001b[0m, in \u001b[0;36mImage.decode_example\u001b[0;34m(self, value, token_per_repo_id)\u001b[0m\n\u001b[1;32m    185\u001b[0m             image \u001b[38;5;241m=\u001b[39m PIL\u001b[38;5;241m.\u001b[39mImage\u001b[38;5;241m.\u001b[39mopen(bytes_)\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 187\u001b[0m     image \u001b[38;5;241m=\u001b[39m \u001b[43mPIL\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mImage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mBytesIO\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbytes_\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    188\u001b[0m image\u001b[38;5;241m.\u001b[39mload()  \u001b[38;5;66;03m# to avoid \"Too many open files\" errors\u001b[39;00m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m image\u001b[38;5;241m.\u001b[39mgetexif()\u001b[38;5;241m.\u001b[39mget(PIL\u001b[38;5;241m.\u001b[39mImage\u001b[38;5;241m.\u001b[39mExifTags\u001b[38;5;241m.\u001b[39mBase\u001b[38;5;241m.\u001b[39mOrientation) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/notebooks/venv/lib/python3.11/site-packages/PIL/Image.py:3309\u001b[0m, in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   3307\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(message)\n\u001b[1;32m   3308\u001b[0m msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot identify image file \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (filename \u001b[38;5;28;01mif\u001b[39;00m filename \u001b[38;5;28;01melse\u001b[39;00m fp)\n\u001b[0;32m-> 3309\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m UnidentifiedImageError(msg)\n",
      "\u001b[0;31mUnidentifiedImageError\u001b[0m: cannot identify image file <_io.BytesIO object at 0x7f117ee3f3d0>"
     ]
    }
   ],
   "source": [
    "# To avoid making stupid errors\n",
    "CURR_TASK = \"B\"\n",
    "\n",
    "# For storing the model\n",
    "best_val_metric = -np.inf\n",
    "\n",
    "# Move model to device\n",
    "model.to(device)\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    model.train()\n",
    "    train_running_loss = 0.0\n",
    "    val_running_loss = 0.0\n",
    "\n",
    "    # Set up tqdm for the training loop\n",
    "    train_loader = tqdm(\n",
    "        dataloaders[CURR_TASK][\"train\"], desc=f\"Epoch {epoch + 1}/{NUM_EPOCHS} Training\"\n",
    "    )\n",
    "\n",
    "    for batch in train_loader:\n",
    "        # Move everything to the device\n",
    "        batch[\"pixel_values\"] = batch[\"pixel_values\"].to(device)\n",
    "        batch[\"pixel_mask\"] = batch[\"pixel_mask\"].to(device)\n",
    "        batch[\"mask_labels\"] = [entry.to(device) for entry in batch[\"mask_labels\"]]\n",
    "        batch[\"class_labels\"] = [entry.to(device) for entry in batch[\"class_labels\"]]\n",
    "\n",
    "        # Compute output and loss\n",
    "        outputs = model(**batch)\n",
    "\n",
    "        loss = outputs.loss\n",
    "\n",
    "        # Compute gradient and perform step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Record losses\n",
    "        current_loss = loss.item() * batch[\"pixel_values\"].size(0)\n",
    "        train_running_loss += current_loss\n",
    "        train_loader.set_postfix(loss=f\"{current_loss:.4f}\")\n",
    "\n",
    "        # Extract and compute metrics\n",
    "        pred_maps, masks = m2f_extract_pred_maps_and_masks(\n",
    "            batch, outputs, m2f_preprocessor_B\n",
    "        )\n",
    "        metric.add_batch(references=masks, predictions=pred_maps)\n",
    "\n",
    "    # After compute the batches that were added are deleted\n",
    "    mean_train_iou = metric.compute(\n",
    "        num_labels=NUM_CLASSES, ignore_index=BG_VALUE, reduce_labels=False\n",
    "    )[\"mean_iou\"]\n",
    "\n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    val_loader = tqdm(\n",
    "        dataloaders[CURR_TASK][\"val\"], desc=f\"Epoch {epoch + 1}/{NUM_EPOCHS} Validation\"\n",
    "    )\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            # Move everything to the device\n",
    "            batch[\"pixel_values\"] = batch[\"pixel_values\"].to(device)\n",
    "            batch[\"pixel_mask\"] = batch[\"pixel_mask\"].to(device)\n",
    "            batch[\"mask_labels\"] = [entry.to(device) for entry in batch[\"mask_labels\"]]\n",
    "            batch[\"class_labels\"] = [\n",
    "                entry.to(device) for entry in batch[\"class_labels\"]\n",
    "            ]\n",
    "            # Compute output and loss\n",
    "            outputs = model(**batch)\n",
    "\n",
    "            loss = outputs.loss\n",
    "            # Record losses\n",
    "            current_loss = loss.item() * batch[\"pixel_values\"].size(0)\n",
    "            val_running_loss += current_loss\n",
    "            val_loader.set_postfix(loss=f\"{current_loss:.4f}\")\n",
    "\n",
    "            # Extract and compute metrics\n",
    "            pred_maps, masks = m2f_extract_pred_maps_and_masks(\n",
    "                batch, outputs, m2f_preprocessor_B\n",
    "            )\n",
    "            metric.add_batch(references=masks, predictions=pred_maps)\n",
    "\n",
    "    # After compute the batches that were added are deleted\n",
    "    mean_val_iou = metric.compute(\n",
    "        num_labels=NUM_CLASSES, ignore_index=BG_VALUE, reduce_labels=False\n",
    "    )[\"mean_iou\"]\n",
    "\n",
    "    epoch_train_loss = train_running_loss / len(dataloaders[CURR_TASK][\"train\"].dataset)\n",
    "    epoch_val_loss = val_running_loss / len(dataloaders[CURR_TASK][\"val\"].dataset)\n",
    "\n",
    "    writer.add_scalar(f\"Loss/train_{model_name}_{CURR_TASK}\", epoch_train_loss, epoch + 1)\n",
    "    writer.add_scalar(f\"Loss/val_{model_name}_{CURR_TASK}\", epoch_val_loss, epoch + 1)\n",
    "    writer.add_scalar(f\"mIoU/train_{model_name}_{CURR_TASK}\", mean_train_iou, epoch + 1)\n",
    "    writer.add_scalar(f\"mIoU/val_{model_name}_{CURR_TASK}\", mean_val_iou, epoch + 1)\n",
    "\n",
    "    wandb.log({\n",
    "        f\"Loss/train_{CURR_TASK}\": epoch_train_loss,\n",
    "        f\"Loss/val_{CURR_TASK}\": epoch_val_loss,\n",
    "        f\"mIoU/train_{CURR_TASK}\": mean_train_iou,\n",
    "        f\"mIoU/val_{CURR_TASK}\": mean_val_iou\n",
    "    })\n",
    "\n",
    "    if mean_val_iou > best_val_metric:\n",
    "        best_val_metric = mean_val_iou\n",
    "        model.save_pretrained(f\"{best_model_dir}{CURR_TASK}/\")\n",
    "\n",
    "    tqdm.write(\n",
    "        f\"Epoch {epoch + 1}/{NUM_EPOCHS}, Train Loss: {epoch_train_loss:.4f}, Train mIoU: {mean_train_iou:.4f}, Validation Loss: {epoch_val_loss:.4f}, Validation mIoU: {mean_val_iou:.4f}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "60a8924e-6370-460c-8af1-a05789ccdaa1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([270, 480])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masks[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "144a9fe7-ae84-4667-9352-ec354126b3ba",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pred_maps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "87cc5d60-7f3a-4e10-9668-ea95b7f0957f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0]], dtype=torch.int32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masks[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "26a41f42-3f7e-433d-88ba-17d85782b722",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = Mask2FormerForUniversalSegmentation.from_pretrained(f\"{best_model_dir}{CURR_TASK}/\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5874f96a-ec6b-4f08-ad37-e4785cc21db0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test loop: 100%|██████████| 14/14 [00:11<00:00,  1.23it/s, loss=166.3146]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 8.7681, Test mIoU: 0.8503\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "test_running_loss = 0\n",
    "test_loader = tqdm(dataloaders[CURR_TASK][\"test\"], desc=\"Test loop\")\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        # Move everything to the device\n",
    "        batch[\"pixel_values\"] = batch[\"pixel_values\"].to(device)\n",
    "        batch[\"pixel_mask\"] = batch[\"pixel_mask\"].to(device)\n",
    "        batch[\"mask_labels\"] = [entry.to(device) for entry in batch[\"mask_labels\"]]\n",
    "        batch[\"class_labels\"] = [entry.to(device) for entry in batch[\"class_labels\"]]\n",
    "        # Compute output and loss\n",
    "        outputs = model(**batch)\n",
    "\n",
    "        loss = outputs.loss\n",
    "        # Record losses\n",
    "        current_loss = loss.item() * batch[\"pixel_values\"].size(0)\n",
    "        test_running_loss += current_loss\n",
    "        test_loader.set_postfix(loss=f\"{current_loss:.4f}\")\n",
    "\n",
    "        # Extract and compute metrics\n",
    "        pred_maps, masks = m2f_extract_pred_maps_and_masks(\n",
    "            batch, outputs, m2f_preprocessor_B\n",
    "        )\n",
    "        metric.add_batch(references=masks, predictions=pred_maps)\n",
    "\n",
    "# After compute the batches that were added are deleted\n",
    "test_metrics_B = metric.compute(\n",
    "    num_labels=NUM_CLASSES, ignore_index=BG_VALUE, reduce_labels=False\n",
    ")\n",
    "mean_test_iou = test_metrics_B[\"mean_iou\"]\n",
    "final_test_loss = test_running_loss / len(dataloaders[CURR_TASK][\"test\"].dataset)\n",
    "wandb.log({\n",
    "    f\"Loss/test_{CURR_TASK}\": final_test_loss,\n",
    "    f\"mIoU/test_{CURR_TASK}\": mean_test_iou\n",
    "})\n",
    "print(f\"Test Loss: {final_test_loss:.4f}, Test mIoU: {mean_test_iou:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "deaa3474-aadd-43f4-9b00-1ce306274b08",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test loop: 100%|██████████| 36/36 [00:31<00:00,  1.15it/s, loss=1304.7112]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 64.4713, Test mIoU: 0.4018\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Loss/test_B</td><td>▁</td></tr><tr><td>Loss/test_naive_forgetting_A</td><td>▁</td></tr><tr><td>Loss/train_B</td><td>█▅▄▃▃▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Loss/val_B</td><td>█▄▃▃▂▂▂▂▂▂▁▂▁▂▁▂▂▁▁▁▂▁▁▂▂▁▁▁▁▁▂▂▁▂▁▁▁▁▁▁</td></tr><tr><td>mIoU/test_B</td><td>▁</td></tr><tr><td>mIoU/test_naive_forgetting_A</td><td>▁</td></tr><tr><td>mIoU/train_B</td><td>▁▄▅▆▆▇▇▇▇▇▇█████▇██████████████▇▇███████</td></tr><tr><td>mIoU/val_B</td><td>▁▅▆▆▆▇▆▆▇▆▆▆▆▆▆▇▇▇▆▅▇▅▆▆▄▇▆▇▇█▇▄▆█▇▇▆▇▇▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Loss/test_B</td><td>8.76806</td></tr><tr><td>Loss/test_naive_forgetting_A</td><td>64.47129</td></tr><tr><td>Loss/train_B</td><td>3.68717</td></tr><tr><td>Loss/val_B</td><td>7.80043</td></tr><tr><td>mIoU/test_B</td><td>0.8503</td></tr><tr><td>mIoU/test_naive_forgetting_A</td><td>0.4018</td></tr><tr><td>mIoU/train_B</td><td>0.88872</td></tr><tr><td>mIoU/val_B</td><td>0.77205</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">M2F-Swin-Tiny-Naive-Forgetting-200</strong> at: <a href='https://wandb.ai/continual-learning-tum/M2F_original/runs/tr1kxq1j' target=\"_blank\">https://wandb.ai/continual-learning-tum/M2F_original/runs/tr1kxq1j</a><br/> View project at: <a href='https://wandb.ai/continual-learning-tum/M2F_original' target=\"_blank\">https://wandb.ai/continual-learning-tum/M2F_original</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240516_001126-tr1kxq1j/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# To avoid making stupid errors\n",
    "CURR_TASK = \"A\"\n",
    "\n",
    "model.eval()\n",
    "test_running_loss = 0\n",
    "test_loader = tqdm(dataloaders[CURR_TASK][\"test\"], desc=\"Test loop\")\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        # Move everything to the device\n",
    "        batch[\"pixel_values\"] = batch[\"pixel_values\"].to(device)\n",
    "        batch[\"pixel_mask\"] = batch[\"pixel_mask\"].to(device)\n",
    "        batch[\"mask_labels\"] = [entry.to(device) for entry in batch[\"mask_labels\"]]\n",
    "        batch[\"class_labels\"] = [entry.to(device) for entry in batch[\"class_labels\"]]\n",
    "        # Compute output and loss\n",
    "        outputs = model(**batch)\n",
    "\n",
    "        loss = outputs.loss\n",
    "        # Record losses\n",
    "        current_loss = loss.item() * batch[\"pixel_values\"].size(0)\n",
    "        test_running_loss += current_loss\n",
    "        test_loader.set_postfix(loss=f\"{current_loss:.4f}\")\n",
    "\n",
    "        # Extract and compute metrics\n",
    "        pred_maps, masks = m2f_extract_pred_maps_and_masks(\n",
    "            batch, outputs, m2f_preprocessor_A\n",
    "        )\n",
    "        metric.add_batch(references=masks, predictions=pred_maps)\n",
    "        \n",
    "# After compute the batches that were added are deleted\n",
    "test_metrics_forgetting_A = metric.compute(\n",
    "    num_labels=NUM_CLASSES, ignore_index=BG_VALUE, reduce_labels=False\n",
    ")\n",
    "mean_test_iou = test_metrics_forgetting_A[\"mean_iou\"]\n",
    "final_test_loss = test_running_loss / len(dataloaders[CURR_TASK][\"test\"].dataset)\n",
    "wandb.log({\n",
    "    f\"Loss/test_naive_forgetting_{CURR_TASK}\": final_test_loss,\n",
    "    f\"mIoU/test_naive_forgetting_{CURR_TASK}\": mean_test_iou\n",
    "})\n",
    "print(f\"Test Loss: {final_test_loss:.4f}, Test mIoU: {mean_test_iou:.4f}\")\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "37453282-d800-47a6-9a4d-88cd5ffd3767",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/notebooks/continual-learning/wandb/run-20240516_070714-baz5l998</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/continual-learning-tum/M2F_original/runs/baz5l998' target=\"_blank\">M2F-Swin-Tiny-Naive-Forgetting-all-results</a></strong> to <a href='https://wandb.ai/continual-learning-tum/M2F_original' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/continual-learning-tum/M2F_original' target=\"_blank\">https://wandb.ai/continual-learning-tum/M2F_original</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/continual-learning-tum/M2F_original/runs/baz5l998' target=\"_blank\">https://wandb.ai/continual-learning-tum/M2F_original/runs/baz5l998</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/continual-learning-tum/M2F_original/runs/baz5l998?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7f114c9449d0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(\n",
    "    project=\"M2F_original\",\n",
    "    config={\n",
    "        \"learning_rate\": LEARNING_RATE,\n",
    "        \"learning_rate_multiplier\": LR_MULTIPLIER,\n",
    "        \"backbone_learning_rate\": BACKBONE_LR,\n",
    "        \"learning_rate_scheduler\": scheduler.__class__.__name__,\n",
    "        \"optimizer\": optimizer.__class__.__name__,\n",
    "        \"backbone\": \"m2f_swin_backbone_train_cadis\",\n",
    "        \"m2f_preprocessor\": m2f_preprocessor_B.__dict__,\n",
    "        \"m2f_model_config\": model.config\n",
    "    },\n",
    "    name=\"M2F-Swin-Tiny-Naive-Forgetting-all-results\",\n",
    "    notes=\"M2F with tiny Swin backbone pretrained on ImageNet-1K. \\\n",
    "        Scenario: Pretrained on A, Train on B, Test forgetting on A\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "add47fcd-bac0-4666-8d46-389278b0210f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**** Overall mIoU ****\n",
      "mIoU on task A: 0.7352255713541009\n",
      "mIoU on task B: 0.8503015788034922\n",
      "mIoU on task A after training on B: 0.4017984503336052\n",
      "\n",
      "**** Per category mIoU ****\n",
      "Per category mIoU on task A: [0.         0.94635122 0.71503252 0.70157295 0.52939948 0.84239861\n",
      " 0.79553573 0.78785687 0.89455109 0.94140952 0.9333733 ]\n",
      "Per category mIoU on task B: [0.         0.70445866 0.3408371  0.21008035 0.0307262  0.41182026\n",
      " 0.45926575 0.53111568 0.80600993 0.38888299 0.53658605]\n",
      "Per category mIoU on task A after training on B: [0.         0.70445866 0.3408371  0.21008035 0.0307262  0.41182026\n",
      " 0.45926575 0.53111568 0.80600993 0.38888299 0.53658605]\n",
      "\n",
      "**** Average learning accuracies ****\n",
      "Average learning acc.: 0.7927635750787966\n",
      "Per category Average learning acc.: [0.         0.82540494 0.52793481 0.45582665 0.28006284 0.62710943\n",
      " 0.62740074 0.65948627 0.85028051 0.66514626 0.73497967]\n",
      "\n",
      "**** Forgetting ****\n",
      "Total forgetting: 0.33342712102049576\n",
      "Per category forgetting: [0.         0.24189256 0.37419542 0.49149261 0.49867328 0.43057835\n",
      " 0.33626997 0.25674119 0.08854116 0.55252653 0.39678725]\n"
     ]
    }
   ],
   "source": [
    "# Collect overall mIoU\n",
    "mIoU_A = test_metrics_A[\"mean_iou\"]\n",
    "mIoU_forgetting_A = test_metrics_forgetting_A[\"mean_iou\"]\n",
    "mIoU_B = test_metrics_B[\"mean_iou\"]\n",
    "\n",
    "# Collect per category mIoU\n",
    "per_category_mIoU_A = np.array(test_metrics_A[\"per_category_iou\"])\n",
    "per_category_mIoU_forgetting_A = np.array(test_metrics_forgetting_A[\"per_category_iou\"])\n",
    "per_category_mIoU_B = np.array(test_metrics_forgetting_A[\"per_category_iou\"])\n",
    "\n",
    "# Average learning accuracies (mIoUs)\n",
    "avg_learning_acc = (mIoU_A + mIoU_B) / 2\n",
    "per_category_avg_learning_acc = (per_category_mIoU_A + per_category_mIoU_B) / 2\n",
    "\n",
    "# Forgetting\n",
    "total_forgetting = mIoU_A - mIoU_forgetting_A\n",
    "per_category_forgetting = (per_category_mIoU_A - per_category_mIoU_forgetting_A)\n",
    "\n",
    "# Export evaluation metrics to WandB\n",
    "wandb.log({\n",
    "    \"eval/avg_learning_acc\": avg_learning_acc,\n",
    "    \"eval/per_category_avg_learning_acc\": per_category_avg_learning_acc,\n",
    "    \"eval/total_forgetting\": total_forgetting,\n",
    "    \"eval/per_category_forgetting\": per_category_forgetting\n",
    "})\n",
    "\n",
    "print(\"**** Overall mIoU ****\")\n",
    "print(f\"mIoU on task A: {mIoU_A}\")\n",
    "print(f\"mIoU on task B: {mIoU_B}\")\n",
    "print(f\"mIoU on task A after training on B: {mIoU_forgetting_A}\")\n",
    "\n",
    "print(\"\\n**** Per category mIoU ****\")\n",
    "print(f\"Per category mIoU on task A: {per_category_mIoU_A}\")\n",
    "print(f\"Per category mIoU on task B: {per_category_mIoU_B}\")\n",
    "print(f\"Per category mIoU on task A after training on B: {per_category_mIoU_forgetting_A}\")\n",
    "\n",
    "print(\"\\n**** Average learning accuracies ****\")\n",
    "print(f\"Average learning acc.: {avg_learning_acc}\")\n",
    "print(f\"Per category Average learning acc.: {per_category_avg_learning_acc}\")\n",
    "\n",
    "print(\"\\n**** Forgetting ****\")\n",
    "print(f\"Total forgetting: {total_forgetting}\")\n",
    "print(f\"Per category forgetting: {per_category_forgetting}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6deb6073-20d9-4824-82a5-f97a15ebd20d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Assuming masks and pred_maps are lists of PyTorch tensors\n",
    "\n",
    "# Save masks\n",
    "torch.save(masks, 'masks.pth')\n",
    "\n",
    "# Save pred_maps\n",
    "torch.save(pred_maps, 'pred_maps.pth')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
